---
title: "大数の法則と中心極限定理"
shorttitle: "NHST, LLN, CLT"
author: "Greg Nishihara"
date: today
date-format: "YYYY / MM / DD"
slide-number: true
transition: slide
progress: true
fig-align: center
format: revealjs
editor: 
  markdown: 
    wrap: 72
bibliography: references.bib
execute: 
  cache: true
  echo: false
  
---

```{r}
#| include: false
#| cache: false
#| echo: false
library(tidyverse)
library(tikzDevice)
library(lemon)
library(ggrepel)
library(ggpubr)
library(knitr)
library(kableExtra)
options(knitr.kable.NA = '')
Sys.setlocale("LC_TIME", "en_US.UTF-8") # This is to set the server time locate to en_US.UTF-8
```


## 大数の法則

**Law of large numbers (大数の法則)**

::: {.callout-note}
# 大数の法則は、
ランダムな試行を繰り返す回数が増えるにつれて、
試行の平均的な結果がその試行の期待値により近づいていく過程です。

つまり、ランダムな出来事は時間の経過とともに均等になる傾向があるという考えに基づいています。
:::



## 大数の弱法則 {.smaller}

**Weak law of large numbers (大数の弱法則)**


$$
\overline{X}_n \xrightarrow{P} \mu \; \text{when}\; n\rightarrow \infty
$$

or,

$$
\forall{\epsilon}>0;\;\lim_{n\rightarrow\infty}P(|\overline{X}-\mu|<\epsilon)=1
$$

::: {.callout-note}
# 大数の弱法則

観測回数が増えるにつれて、標本平均は確率収束に従って母集団平均に収束していきます。
つまり、標本の大きさが増えるにつれて、標本平均が母集団平均に近くなる確率が高くなります。
:::




::: {.notes}

- The sample mean X-bar converges in probability to the population mean mu as the sample size n approaches infinity.
- 標本平均 X-bar が、標本サイズ n が無限に近づくにつれて、確率収束において母集団平均 mu に収束する。
- For any positive value of epsilon, the probability that the sample mean (X-bar) will be within epsilon of the population mean (mu) approaches 1 as the sample size approaches infinity.
- 任意の正の値 エプシロン に対して、標本平均 (X-bar) が母集団平均 (ミュー) から エプシロン の範囲内にある確率が、標本サイズが無限に近づくにつれて1に収束する」という意味です。

:::

## 大数の強法則

**Strong law of large numbers (大数の強法則)**

$$
\overline{X}_n \xrightarrow{a.s.} \mu \; \text{when}\; n\rightarrow \infty
$$

or

$$
P(\lim_{n\rightarrow\infty}\overline{X}=\mu)=1
$$

::: {.notes}

- The sample mean X-bar converges almost surely to the population mean mu as the sample size n approaches infinity.
- 標本平均 X-bar が、標本サイズ n が無限に近づくにつれて、ほとんど確実に母集団平均 mu に収束する。

- The probability that the sample mean X-bar will approach the population mean mu as the sample size approaches infinity is equal to 1.
- 標本サイズが無限に近づくにつれて、標本平均 X-bar が母集団平均 mu に近づく確率は1に等しい。

:::

## コインの裏表デモ

:::: {.columns}
::: {.column width="50%"}

```{r}
#| fig-width: 6
#| fig-height: 6
# Load the libraries
library(ggplot2)
library(gganimate)
library(tidyverse)
library(patchwork)
n_trials <- 10
make_data = function(n_trials = 10) {
  tibble(data = rbinom(n_trials, size = 1, prob = 0.5)) |> mutate(color = factor(data))
}
p1 = ggplot(data = make_data(), aes(x = 1:n_trials, y = 1, color = color)) +
  geom_point(size = 10, show.legend = F) +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
p2 = ggplot(data = make_data(), aes(x = 1:n_trials, y = 1, color = color)) +
  geom_point(size = 10, show.legend = F) +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
p3 = ggplot(data = make_data(), aes(x = 1:n_trials, y = 1, color = color)) +
  geom_point(size = 10, show.legend = F) +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
p1 + p2 + p3 + plot_layout(ncol = 1)
```

:::
::: {.column width="50%"}

```{r}
#| fig-width: 6
#| fig-height: 6
set.seed(2023)
pout = 
  tibble(size = c(seq(5, 5000, by = 5))) |> 
  mutate(ones = map_int(size, rbinom, n = 1, prob = 0.5)) |> 
  mutate(zeros = size - ones) |> 
  mutate(ratio = ones / zeros) |> 
  ggplot() + 
  geom_segment(aes(x = size, xend = size, y = 1, yend = ratio), linewidth = 2) +
  scale_x_continuous("Number of coin flips") +
  scale_y_continuous("Ratio") +
  transition_reveal(size) +
  shadow_trail(color = "orangered", distance = 0.005)
  
animate(pout, nframes = 200, width = 400, height = 400)
```
:::
::::


## 平均値のデモ

:::: {.columns}
::: {.column width="50%"}
```{r}
#| fig-width: 6
#| fig-height: 6
mu = 10
sigma2 = mu^2
n = 2:1000
fn1 = function(n,mu,sd) mean(rnorm(n, mu, sd))
m = sapply(n, fn1,mu=mu,sd=sqrt(sigma2))
df1 = data.frame(m = m, n = n)
ggplot(df1) +
  geom_line(aes(x=n,y=m), size = 0.1) +
  geom_hline(yintercept = mu, 
             color = "orangered") +
  scale_x_continuous("データ数 (n)") +
  scale_y_continuous("平均値",
                     limits = c(floor(min(df1$m)), ceiling(max(df1$m))),
                     breaks = c(floor(min(df1$m)), mu, ceiling(max(df1$m)))) +
    geom_text_repel(aes(x=n, y=mu, label = label), 
                  data = tibble(n = 500, mu = mu,
                                label = "真の平均値 (μ = 10)"),
                  color = "navy",
                  ylim = c(14),
                  xlim = c(250))
```
:::
::: {.column width="50%"}

* True mean $\mu=10$

* True variance $\sigma^2 = 10^2$

* Number of data ranged from $1$ to $1000$

**R Code for the pseudo-random values from the normal distribution**

```{r}
#| eval: false
#| echo: true
mu = 10              # 真の平均値
sd = 10              # 真の標準偏差
n = 5                # データ回数
m = rnorm(n, mu, sd) # 正規分布の疑似乱数
```

:::
::::

# Central limit theorem

## 中心極限定理

中心極限定理とは、多数の独立かつ同一分布に従う確率変数の平均値の分布が、
一定の条件下では、正規分布に近似することを示す。

データの分布に関わらず、データの平均値を大量に求めると、その平均値自体が正規分布に近似することが期待できる。
平均値は、正規分布に従うことで、母集団の平均値や分散についての推論ができるようになる。

統計学において非常に重要な定理です。


## Central limit theorem (中心極限定理)


$$
\lim_{n\rightarrow \infty}\sqrt{n}\left(\frac{\overline{X}_n - \mu}{\sigma}\right) \xrightarrow{d} N(0, \sigma^2)
$$


::: {.notes}
This equation expresses that as the sample size $n$ approaches infinity, the standardized sample mean $\frac{\overline{X}_n - \mu}{\sigma}$ multiplied by $\sqrt{n}$ approaches a normal distribution with mean $0$ and variance $\sigma^2$.

この式は、標本数 $n$ が無限大に近づくにつれて、$\sqrt{n}$ と $\frac{\overline{X}_n - \mu}{\sigma}$ の積は、平均 $0$、分散 $\sigma^2$ の正規分布に近づくことを表す。

:::


## サイコロのデモ

:::: {.columns}
::: {.column width="50%"}

* 各試行は6つのサイコロの出目の平均です。
* $N$ が増えるにつれて、標本平均は正規分布に収束します（中心極限定理）。
* 大数の法則により、標本平均は真の平均値（$\mu = 3.5$）に収束することが保証されます。

:::
::: {.column width="50%"}

```{r clt-animation-prep, echo = F, fig.height = 5, fig.width = 5, out.width = "80%"}
set.seed(2020)
N=c(5, 10, 100, 10^3, 10^4, 10^5)
X = tibble(n = N) |> 
  mutate(x = map(n, function(x) {
    replicate(x, mean(sample(1:6, 5, replace = TRUE), na.rm = T))
  })) |> mutate(state = (n))

X = X |> unnest(x)
Y = X |> group_by(state) |> summarise(m = mean(x))

wraplabel = function(x) sprintf("試行回数 = %s",x)

ggplot(X , aes(x = x, group = state)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.2) +
  stat_function(fun = dnorm, args = list(mean = 3.5, sd = 0.8)) +
  scale_y_continuous("確率密度") +
  scale_x_continuous("平均値", limits = c(1, 6), breaks = 1:6) +
  geom_vline(aes(xintercept = m, group = state), data = Y, color = "orangered") +
  facet_wrap("state", labeller = as_labeller(wraplabel)) +
  ggtitle("試行回数が増えると真の平均値に収束しする")
```

:::
::::

## Binomial distribution


The mean and variance of the binomial distribution (二項分布)

* $\mu=np$
* $\sigma^2 = np(1-p)$


## Demonstration

:::: {.columns}
::: {.column width="50%"}

```{r, echo=FALSE}
p = 0.45
n = 40
m = c(10,100,200,500)

df1 = tibble(m = c(5,10,50,10000)) |> 
  mutate(data = map(m, function(x) {
    p = 0.45
    n = 40
    tibble(r = replicate(x, rbinom(1,n,p)))
  }))

df1 |> unnest(data) |> 
  ggplot() +
  geom_histogram(aes(x = r, y = ..density..),
                 binwidth = 1) +
  stat_function(fun = dnorm, args = list(mean = n*p, sd = sqrt(n*p*(1-p)))) +
  scale_x_continuous(limit = c(0, 40)) + 
  facet_wrap("m")

```


:::
::: {.column width="50%"}

* $n = 40$
* $p = 0.45$
* number of trials = 100,000
* $np = `r n*p`$ (mean)
* $np(1-p) = `r n*p*(1-p)`$ (variance)

:::
::::


# Scientific Method

## Scientific Method (科学的方法)　{.smaller}

合理的に研究をするためには、科学的方法を用います。
科学的方法には6つのステップがあり、切り返して行うことが一般的です。

- 観察：まず、自然界を観察します。
- 質問：観察した自然現象について、科学的に検証できる（実験）課題を考えます。
- 仮説：仮説は、質問に対する合理的な推測です。実験で検証できるものです。
- 実験：実験を行い、考えた仮説が正しいかどうかを確認します。ここでデータ収集します。
- 分析：実験で得たデータを統計学的に解析します。データは、考え上げた仮説を支持するか否定するかを検証します。
- 結論：仮説が支持された場合は、考え上げた仮説が現段階で正しいと結論つけられますが、否定された場合は、仮説を修正するかまたは新たな仮説を開発します。

::: {.notes}
科学的方法は周期的なプロセスです。実験を終了した後、最初に戻って新しい観察を行うか、新しい質問をする必要が生じる場合があります。これは、科学的方法が自然界について学ぶ方法だからです。より多くのことを学ぶにつれて、仮説や理論を変更する必要があるかもしれません。

科学的方法は、自然界を理解するための強力なツールです。科学者はこの方法を使用して、原子から銀河までのあらゆるものを理解するための大きな進歩を遂げました。科学的方法は、継続的な学習と発見のプロセスです。それは、自然界の真実を見つける方法です
::: 

## Hypothesis (仮説)

* 仮説は実験を行う前に決めるもの。データ見てから仮説を決めません。
* 一般的には、仮説を証明（採択）したいが、統計学の視点から考えると、仮説は棄却するものです。

**仮説を証明（採択）することはできません。仮説は棄却するものです。**

## Model (モデル)

* モデルはデータを見てから考えるもの。
* モデルも検証する必要があります。
* モデルは予測に使用できます。

## 有意性検定および仮説検定{.smaller}

:::: {.columns}
::: {.column width="50%"}

**Significance testing (有意性検定論)**

* 1920年代に、R.A. Fisher が提案した。
* 帰無仮説 $H_0$　に対して集めたデータを得られるエビデンス（証拠）。
* P値が小さいとき、エビデンスは弱い
    - $\text{P-value} = P(T(X) \ge T_0(X)|H_0)$
* 仮説の棄却や採択はしない

:::
::: {.column width="50%"}

**Hypothesis testing (仮説検定論)**

* 1930年代に、 J. Neyman と E.S. Pearson が提案した。
* 最も使われている手法
* 帰無仮説 $H_0$ と対立仮説 $H_A$を定義します
* 有意水準 (significance level $\alpha$) を基準にして、 $H_A$ の採択または棄却をする手法。

:::
::::


::: {.notes}
Sir Ronald Aylmer Fisher was a British statistician and geneticist. His work win agricultural experiments led to the development of the Analysis of Variance. In 1925 he published the book Statistical Methods for Research Workers, that introduced the concept of the P-value.

Jerzy Neyman was a Polish mathematician and statician, and Egon Sharpe Pearson was a British statician. They co-invented and popularized the hypothesis testing techniques and the rejection and acceptance of the null hypothesis or the alternative hypothesis. 
:::

# The P-value and Hypothesis Test


## What is the P-value (P値とは)? {.smaller}

統計解析をすることで、P値を求めることは当たり前のようになりました。

$$
\text{P-value} = P(T(X) \ge T_0(X)|H_0)
$$


* 帰無仮説 $H_0$ にたいして、$T(X) > T_0(X)$ がおきる確率
* 帰無仮説に対して、収集したデータの整合性を指標科した値
* P値は 0 ~ 1 ($0 \leq \text{P-value} \leq 1$) の範囲をとる。
* 帰無仮説が正しいとき、P値は一様分布に従う。
* 帰無仮説が正しくとき：$\displaystyle \lim_{n \rightarrow \infty} P \rightarrow 0$。

::: {.notes}

- The P-value only makes sense when the null hypothesis is true. This is why we assume a true null, so that we can get a P-value.
- The original definition of the P-value: the chance of obtaining an effect equal to or more extreme than the one observed considering the null hypothesis is true.

**Links to StackExchange: Cross Validated Questions.**S

- [Intepretation of p-value in hypothesis testing.](https://stats.stackexchange.com/questions/46856/interpretation-of-p-value-in-hypothesis-testing)
- [What is the relationship between p values and type I errors](https://stats.stackexchange.com/questions/129628/what-is-the-relationship-between-p-values-and-type-i-errors)
- [How do I find the probability of type II errors](https://stats.stackexchange.com/questions/7402/how-do-i-find-the-probability-of-a-type-ii-error/7404)

:::

## P-value distribution when $H_0$ is true

```{r}
#| echo: false
#| warning: false
#| message: false
t_test = function(x) {t.test(x$x1, x$x2, var.equal = TRUE)}
X= tibble(n = 1:10000) |> 
  mutate(data = map(n, function(x) {
    tibble(x1 = rnorm(10, mean = 50),
           x2 = rnorm(10, mean = 50))
  })) |> 
  mutate(tout = map(data, t_test)) |> 
  mutate(tout2 = map(tout, broom::glance)) |> 
  unnest(tout2) 
X |> 
  ggplot() +
  geom_histogram(aes(x = p.value), binwidth = 0.05) + 
  geom_vline(xintercept = 0.05, color = "orangered") +
  scale_x_continuous("P-values") + 
  scale_y_continuous("") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.title = element_blank(), 
        panel.grid = element_blank())
x = X |> summarise(cnt = sum(p.value < 0.05) / length(p.value))
```

**When the null hypothesis is true, ($(\mu_0=50) = (\mu_A=50)$) and the P-value has a uniform distribution.**
For 10000 simulations $P(\text{P-value}<0.05) = `r round(x, 4)`$.

## P-value distribution when $H_0$ is false

```{r}
#| echo: false
#| warning: false
#| message: false

t_test = function(x) {t.test(x$x1, x$x2, var.equal = TRUE)}

X = tibble(n = 1:10000) |> 
  mutate(data = map(n, function(x) {
    tibble(x1 = rnorm(10, mean = 50),
           x2 = rnorm(10, mean = 51))
  })) |> 
  mutate(tout = map(data, t_test)) |> 
  mutate(tout2 = map(tout, broom::glance)) |> 
  unnest(tout2)
X |> 
  ggplot() +
  geom_histogram(aes(x = p.value)) + 
  geom_vline(xintercept = 0.05, color = "orangered") +
  scale_x_continuous("P-values") +
  scale_y_continuous("") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.title = element_blank(), 
        panel.grid = element_blank())
x = X |> summarise(cnt = sum(p.value <= 0.05) / length(p.value))  
```

**When the null hypothesis is false, ($(\mu_0=50) \ne (\mu_A=51)$), and the P-value approaches 0.**
For 10000 simulations$P(\text{P-value}<0.05) = `r round(x, 4)`$.
However, the Type-II error rate (第 2 種の誤り) is `r round(1-x, 4)`.

## 仮説検定


**仮説検定は客観的に意思決定をするために使います。**

* P値は帰無仮説と対立仮説を比較するために使います。
* 帰無仮説を棄却するルールは有意水準を用いて行います。
* $\text{P-value} \leq \alpha$　のとき帰無仮説を棄却します。
* 帰無仮説を棄却・採択することで、誤りを起こすことになる
    - 第１種の誤り, α過誤 (Type-I error)
    - 第２種の誤り, β過誤 (Type-II error)

## 帰無仮説にきをつけろ！

Neyman-Pearson の仮説検定法は **Null Hypothesis Significance Test (NHST) (帰無仮説の有意性検定)** といいます。
意思決定をするための手法なので、誤りを起こすこともある

* **Type-I Error (第１種の誤り):** 帰無仮説が正しいのに、帰無仮説を棄却する誤り。誤る確率は $\alpha$　（有意水準と同じ値）
* **Type-II Error (第２種の誤り):** 帰無仮説が正しくないのに、帰無仮説を棄却しない誤り。誤る確率は $\beta$（単純に求められない）

## 帰無仮説にきをつけろ！

* $\alpha$ 有意水準および第1種の誤り
* $\beta$ 第2種の誤り
* $1-\beta$ 検定の検出力、正しくない帰無仮説を棄却する確率
* 第1種の誤りを厳しくすると、第2種の誤りはあまくなる (お互いに反比例する)

$$
\alpha \propto 1/\beta
$$


## Type-I and II error: Correctly rejecting a test

```{r}
#| echo: false
#| eval: true
A = c(0.05, 0.10)
B = c(0.36, 0.24)
c1 = 900 * A # 誤って棄却
c2 = 900 - c1 # 正しく棄却
c4 = 100 * B # 誤って棄却しない
c3 = 100 - c4 # 正しく棄却
rat = c3 / (c3+c1)
```

```{r}
#| echo: false
#| cache: false
#| fig-align: center

magick::image_read_pdf("~/Documents/QTIKZ/statchart.pdf") |> 
  magick::image_border(color = "white")

```


::: {.notes}

[Biau et al. 2010. Clin. Orthop. Relat. Res. 468: 885-892.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2816758/)

Fig. 2 of Biau et al. 2010 is wrong, since if the Type-I error rate decreases, then the Type-II error rate increases.

There is a false impression that if experiments are conducted with a low Type I error, then significant results almost always corresponds to a true effect. 

Out of 1000 null hypothesis, 10% are actually false. 
In otherwords, the null hypothesis is rarely false.
So, 900 are true null hypothesis and 100 are false null hypothesis.
However, we do not know this.
Suppose that we perform tests that have an α of 0.10 and a β of 0.24,
Among the true null hypothesis, since our Type-I error rate is 0.10, then 90 experiments will be erroneously rejected.
Among the false null hypothesis, since our Type-II error rate is 0.24, then 24 experiments will be
erroneously not rejected and 80 will be correctly rejected.

Therefore, a total of 90+76 null hypotheses will be rejected, but only 76 / (90+76) = 0.46 of these were correctly rejected.

**I am not sure if this is a good example, since the null hypothesis is only rare false. What is the point of this?**

:::

## 有意性検定と仮説検定の違い {.smaller}

:::: {.columns}
::: {.column width="50%"}

**Significance testing (有意性検定)**

* Fisher の手法
* P値の値は重要
* 帰無仮説を棄却するために使う
* データを見てから計算する
* 解析したデータのみに有効
* Subjective decision (主観的な判断)
* エビデンスによる意思決定

:::
::: {.column width="50%"}

**NHST (仮説検定)**

* Neyman and Pearson の手法
* 第1種の誤りが重要
* 第1種と第2種の誤りを最低限にする
* データを見てから、α と β を選ぶ
* 実験は十分に反復されており、今後も似たようなデータを期待できる
* Objective decision (客観的)
* ルールに基づいた意思決定

:::
::::

Most scientists mix the two methods, which is wrong!


::: {.notes}

- [Biau et al. 2010. Clin. Orthop. Relat. Res. 468: 885-892.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2816758/)

See Fig. 1A-B in this paper. Since Fisher's P-value is valid for each experiment
individually, some experiments will provide evidence for rejecting the null and some won't.

- The p value is not the probability of the null hypothesis being true; it is the probability of observing these data, or more extreme data, if the null is true.
- However, for Neyman-Pearson method, there is only a chance of making an error of rejecting or accepting a hypothesis based on an α and β value.

:::


# Introduction to the Null Hypothesis Significance Test (NHST)


## Example {.smaller}

:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: false
set.seed(2020)
data = tibble(experiment = LETTERS[1:2]) |> 
  mutate(data = map(experiment, function(x) {
    mu = ifelse(x == "A", 10, 12)
    tibble(observation = rnorm(20, 10))
  })) |> 
  unnest(data)
data |> 
  ggplot(aes(x = experiment, y = observation)) + 
  geom_boxplot(width = 0.5) +
  geom_point(position = position_jitter(0.1), color = "orangered") 
```
:::

::: {.column width="50%"}


```{r}
out = t.test(observation ~ experiment, data = data)
t.test(observation ~ experiment, data = data)
```

* $H_0: \overline{\mu_A}=\overline{\mu_B}~:\text{Null hypothesis}$
* $H_1: \overline{\mu_A}\neq\overline{\mu_B}~:\text{Alternative hypothesis}$
* True standard deviation：$\sigma_A=\sigma_B$
* True mean: $\overline{\mu_A}=10$ and $\overline{\mu_B}=12$
* In this case, $P = `r round(out$p.value, 4)`  \nless \alpha = 0.05$

:::
::::

::: {.notes}
The true means are different, yet the P-value for the Welch's two sample t-test is greater than 0.05.
What does this mean?

Do we accept the alternative hypothesis?

Do we reject the null hypothesis?
:::

## Amerhein et al. 2019. Nature 567: 305-307 {.smaller}

:::: {.columns}
::: {.column width="50%"}


> Let's be clear about what must stop: we should never conclude there is 'no difference' or 'no association' just because a P-value is larger than a threshold such as 0.05 or, equivalently, because a confidense interval includes zero. --Amerhein et al. 2019

:::
::: {.column width="50%"}

```{r}

#| echo: false
set.seed(2020)
data = 
  tibble(experiment = LETTERS[1:2],
         n = c(200, 200),
         sd = c(1, 2)) |> 
  mutate(data = map2(n, sd, function(n, sd) {
    tibble(observation = rnorm(n, 10, sd)) |> 
      mutate(observation = scale(observation, scale=F)[,1] + 10)
  })) |> 
  unnest(data)

data2 = data |> group_by(experiment) |> 
  summarise(ymin = min(observation),
            ymax = max(observation),
            y25 = quantile(observation, 0.25),
            y50 = quantile(observation, 0.50),
            y75 = quantile(observation, 0.75))

data |> 
  ggplot() + 
  geom_boxplot(aes(x = experiment,
                   ymin = ymin, ymax = ymax, middle = y50,
                   lower = y25, upper = y75), 
               stat = "identity",
               width = 0.5,
               data = data2) +
  geom_point(aes(x = experiment, y = observation),
             position = position_jitter(0.1), color = "orangered",
             data = data)  +
  geom_hline(aes(yintercept = 6)) +
  scale_x_discrete("", labels = c("Technician A", "Technician B")) +
  scale_y_continuous("Decreasing effect ⬅　Effect　➡ Increasing effect") +
  coord_flip()

```
:::
::::



