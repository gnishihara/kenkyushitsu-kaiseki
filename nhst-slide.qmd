---
title: |
       | 大数の法則と
       | 中心極限定理
shorttitle: "NHST, LLN, CLT"
author: "Greg Nishihara"
date: today
date-format: "YYYY / MM / DD"
slide-number: true
transition: slide
progress: true
fig-align: center
format: revealjs
html-math-method: mathjax
editor: 
  markdown: 
    wrap: 72
bibliography: references.bib
execute: 
  cache: true
  echo: false
  
---

# Law of large numbers

```{r}
#| include: false
#| cache: false
#| echo: false
library(tidyverse)
library(tikzDevice)
library(lemon)
library(ggrepel)
library(ggpubr)
library(patchwork)
library(knitr)
library(kableExtra)
library(ggtext)
library(showtext)
library(gganimate)
library(magick)

font_add_google("Noto Sans", "notosans")
font_add_google("Noto Sans JP", "notosansjp")
font_add_google("Noto Sans Symbols", "notosanssymbol")
theme_gray(base_family = "notosansjp",
           base_size = 20) |> 
  theme_set()
showtext_auto()
options(knitr.kable.NA = '')
Sys.setlocale("LC_TIME", "en_US.UTF-8") # This is to set the server time locate to en_US.UTF-8
```

## 度数 (frequency)

::: {.callout-note}
## 度数（頻度）とは

ある標本で特定のデータの値が得られた回数。
相対度数は標本数に対する度数の割合です。
:::

```{r}
size = 30
x = sample(1:6, size = size, replace = T)
xm = max(x)
l = sum(xm == x)
s = l/size

text = sprintf("{frac(6~の度数, 標本数) == frac(%d , %d)} == %0.2f",l, size, l/size)

```

`{r} str_c("{", str_flatten_comma(x), "}")` に対する 
`{r} xm` の度数は `{r} l` です。

**相対度数は** 

```{r}
#| results: hide

w = 800
h = 300
img = image_blank(w, h, "white") |> image_border()
img = image_draw(img)
text(w/2,h/2,
     parse(text = text),
     family = "notosansjp", cex = 6)
dev.off()
```


```{r}
#| fig-width: 5
#| fig-height: 2
#| fig-align: "center"

img
```


です。

## コイン投げの例

```{r}
#| fig-width: 4.00
#| fig-height: 2.25
#| fig-align: "center"
set.seed(2024)
size = 20000
x = sample(c(0,1), size = size, replace = T)
y = cumsum(x) / seq_along(x)
dset = tibble(x = seq_along(x), y)
dset |> 
  slice_head(n = 100) |> 
  ggplot() + 
  geom_line(aes(x = x, y = y))+
  scale_x_continuous("投げた回数") +
  scale_y_continuous("表が出る相対度数",
                     limits = c(0, 1))
```

::: {style="font-size:50%;"}
フェア (fair) なコインを投げた場合、表が出る確率は 0.50 です。
では、コインを 100 回投げた場合、
表がでる相対度数は 0.50 でしょうか。
:::

## コイン投げの例

```{r}
#| fig-width: 4.00
#| fig-height: 2.25
#| fig-align: "center"
d1 = dset |> slice(10^c(0,1,2,3,4,5))
d2 = dset |> slice_sample(n = 1000)
bind_rows(d1, d2) |> distinct() |> 
  ggplot() + 
  geom_line(aes(x = x, y = y))+
  scale_x_continuous("投げた回数") +
  scale_y_continuous("表が出る相対度数",
                     limits = c(0, 1))
```

::: {style="font-size:50%;"}
今回の実験では、
表が出る度数が 0.50 に収束するためには、
おおよそ 15,000 回投げました。

コイン投げの回数が少なければ（小数）
表が出る確率と相対度数に大きな違いがありましたが、
投げる回数が増えると（大数）相対度数と確率の違いは小さくなりました。
:::

## 大数の弱法則

**Weak law of large numbers (大数の弱法則)**

::: {style="font-size:50%;"}
平均値 $\mu$、 分散 $\sigma^2$ の分布にお互いに独立に従う
確率変数 $X_1, X_2, \cdots, X_n$ と、任意の $\varepsilon > 0$ 
の場合、
:::

$$
\lim_{n\rightarrow\infty} P \left(\left |\frac{X_1+X_2+\cdots+X_n}{n}-\mu\right | < \varepsilon\right) = 1
$$

::: {style="font-size:50%;"}
つまり、標本平均と母平均の差が $\varepsilon$ 以下になる確率は
試行回数 $(n)$ を増やせば $1$ に**確率収束 (stochastic convergence)** すると意味します。
:::


## 大数の強法則

**Strong law of large numbers (大数の強法則)**


$$
P \left(\lim_{n\rightarrow\infty} \frac{X_1+X_2+\cdots+X_n}{n}=\mu \right) = 1
$$

観測回数が増えるにつれて、標本平均は**概収束（ほとんど確実に収束; almost sure convergence）**に従って母平均に収束します。

## 平均値のデモ

```{r}
#| fig-width: 4
#| fig-height: 2.25
#| fig-align: "center"

y = runif(2^10)
n = seq_along(y)
dset = tibble(n,y)
dset = dset |> 
  mutate(m = cummean(y))

ggplot(dset) + 
  geom_point(aes(n , y),
             stroke = 0, alpha = 0.5) +
  geom_line(aes(n, y = m),
            color = "darkred")

```

::: {style="font-size:50%;"}
標本 (`y`) は 0 から 1 の一様分布に従う確率変数です。
点は `y` の観測値、線は `y` の累積平均値（標本平均）です。
標本数が増えれるにつれて、`y` の標本平均（線）は母平均 (&mu; = 0.50) に収束する。
:::


# Central limit theorem

## {#clt-dice-example1 data-menu-title="CLTサイコロの例1"}

```{r}
dset = table(outer(1:6, 1:6, "+")) |> 
  as.matrix() |> 
  as_tibble(rownames = "n") |> 
  mutate(p = V1/36,
         n = as.integer(n))

dset = dset |> 
  mutate(l = str_c(V1, "/", "36")) |> 
  arrange(p)
ybreaks = dset$p |> unique() 
ylabels = dset$l |> unique() 

p1 = ggplot(dset)+ 
  geom_col(aes(x = n, y = p)) +
  scale_x_continuous("2 個のサイコロの和", breaks = 2:12) +
  scale_y_continuous("確率",
                     breaks = c(0, ybreaks),
                     labels = c("0/36", ylabels))

probability = table(outer(1:6,1:6, "+"))/36
N = 2^15
X = replicate(N,
              sample(
                2:12,
                size = 49,
                replace = T,
                prob = probability
              ))

dset = tibble(x = (apply(X, 2, mean))) |> 
  mutate(s = sd(x))
dset = dset |> 
  mutate(x = (x - 7)/s)

p2 = tibble(dset) |> 
  ggplot( )+
  geom_histogram(aes(x, y = after_stat(density)),
                 bins = 21) +
  geom_function(fun = dnorm,
                color = "orangered") +
  scale_x_continuous("Z値（標準得点, Z-score）") +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )
```

```{r}
#| fig-width: 6
#| fig-height: 2
#| fig-align: "center"
p1 + p2
```

::: {style="font-size:50%;"}

一回の実験に２個のサイコロを４９回投げました。
実験は 2^15^ 回繰り返して行い、実験ごとに２個のサイコロの和の平均値を求めました。
標準平均から母平均（７）を引いたあと、標本の標準偏差で割りました
$(Z = \frac{x_i - \overline{x}}{s})$。
もとのデータの分布は正規分布ではないが、平均値は正規分布に従っています。
:::


## {#clt-dice-example2 data-menu-title="CLTサイコロの例2"}

```{r}
dset = 
  tibble(n = 1:6,
         p = rep(1/6, 6)) |> 
  mutate(l = str_c(1, "/", "6")) |> 
  arrange(p)
ybreaks = dset$p |> unique() 
ylabels = dset$l |> unique() 

p1 = ggplot(dset)+ 
  geom_col(aes(x = n, y = p)) +
  scale_x_continuous("1 個のサイコロ", breaks = 1:6) +
  scale_y_continuous("確率",
                     breaks = c(0, ybreaks),
                     labels = c("0/6", ylabels))

probability = rep(1/6, 6)
N = 2^15
X = replicate(N,
              sample(
                1:6,
                size = 49,
                replace = T,
                prob = probability
              ))

dset = tibble(x = (apply(X, 2, mean))) |> 
  mutate(s = sd(x))
dset = dset |> 
  mutate(x = (x - 3.5)/s)

p2 = tibble(dset) |> 
  ggplot( )+
  geom_histogram(aes(x, y = after_stat(density)),
                 bins = 19) +
  geom_function(fun = dnorm, 
                color = "orangered") +
  scale_x_continuous("Z値（標準得点, Z-score）") +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )
```

```{r}
#| fig-width: 6
#| fig-height: 2
#| fig-align: "center"
p1 + p2
```

::: {style="font-size:50%;"}

一回の実験に 1 個のサイコロを４９回投げました。
実験は 2^15^ 回繰り返して行い、
実験ごとに 1 個のサイコロの出目の平均値を求めました。
標準平均から母平均（3.5）を引いたあと、標本の標準偏差で割りました
$(Z = \frac{x_i - \overline{x}}{s})$。
もとのデータの分布は正規分布ではないが、平均値は正規分布に従っています。
:::


## Central limit theorem (中心極限定理)

中心極限定理とは、多数の独立かつ同一分布に従う確率変数の
平均値の分布が、一定の条件下では、正規分布に近似することを示す。

データの分布に関わらず、データの平均値を大量に求めると、
その平均値自体が正規分布に近似することが期待できる。
平均値は、正規分布に従うことで、母集団の平均値や分散についての
推論ができるようになる。

統計学において非常に重要な定理です。


## 中心極限定理


$$
\lim_{n\rightarrow \infty}\sqrt{n}\left(\frac{\overline{X}_n - \mu}{\sigma}\right) \xrightarrow{d} N(0, \sigma^2)
$$


標本数 $n$ が無限大に近づくにつれて、$\sqrt{n}$ と $\frac{\overline{X}_n - \mu}{\sigma}$ の積は、平均 $0$、分散 $\sigma^2$ の正規分布に近づくことを意味します。

* $\overline{X}_n$ は標本 n の標本平均値です。
* $\xrightarrow{d}$ は法則収束または分布収束 (converges in distribution)　と意味します。


::: {.notes}
This equation expresses that as the sample size $n$ approaches infinity, the standardized sample mean $\frac{\overline{X}_n - \mu}{\sigma}$ multiplied by $\sqrt{n}$ approaches a normal distribution with mean $0$ and variance $\sigma^2$.


:::


# Scientific Method

## Scientific Method (科学的方法)　{.smaller}

合理的に研究をするためには、科学的方法を用います。
科学的方法には6つのステップがあり、切り返して行うことが一般的です。

- 観察：まず、自然界を観察します。
- 質問：観察した自然現象について、科学的に検証できる（実験）課題を考えます。
- 仮説：仮説は、質問に対する合理的な推測です。実験で検証できるものです。
- 実験：実験を行い、考えた仮説が正しいかどうかを確認します。ここでデータ収集します。
- 分析：実験で得たデータを統計学的に解析します。データは、考え上げた仮説を支持するか否定するかを検証します。
- 結論：仮説が支持された場合は、考え上げた仮説が現段階で正しいと結論つけられますが、否定された場合は、仮説を修正するかまたは新たな仮説を開発します。

::: {.notes}
科学的方法は周期的なプロセスです。実験を終了した後、最初に戻って新しい観察を行うか、新しい質問をする必要が生じる場合があります。これは、科学的方法が自然界について学ぶ方法だからです。より多くのことを学ぶにつれて、仮説や理論を変更する必要があるかもしれません。

科学的方法は、自然界を理解するための強力なツールです。科学者はこの方法を使用して、原子から銀河までのあらゆるものを理解するための大きな進歩を遂げました。科学的方法は、継続的な学習と発見のプロセスです。それは、自然界の真実を見つける方法です
::: 

## Hypothesis (仮説)

* 仮説は実験を行う前に決めるもの。データ見てから仮説を決めません。
* 一般的には、仮説を証明（採択）したいが、統計学の視点から考えると、仮説は棄却するものです。

**仮説を証明（採択）することはできません。仮説は棄却するものです。**

## Model (モデル)

* モデルはデータを見てから考えるもの。
* モデルも検証する必要があります。
* モデルは予測に使用できます。

## 有意性検定および仮説検定{.smaller}

:::: {.columns}
::: {.column width="50%"}

**Significance testing (有意性検定論)**

* 1920年代に、R.A. Fisher が提案した。
* 帰無仮説 $H_0$　に対して集めたデータを得られるエビデンス（証拠）。
* P値が小さいとき、エビデンスは弱い
    - $\text{P-value} = P(T(X) \ge T_0(X)|H_0)$
* 仮説の棄却や採択はしない

:::
::: {.column width="50%"}

**Hypothesis testing (仮説検定論)**

* 1930年代に、 J. Neyman と E.S. Pearson が提案した。
* 最も使われている手法
* 帰無仮説 $H_0$ と対立仮説 $H_A$を定義します
* 有意水準 (significance level $\alpha$) を基準にして、 $H_A$ の採択または棄却をする手法。

:::
::::


::: {.notes}
Sir Ronald Aylmer Fisher was a British statistician and geneticist. His work win agricultural experiments led to the development of the Analysis of Variance. In 1925 he published the book Statistical Methods for Research Workers, that introduced the concept of the P-value.

Jerzy Neyman was a Polish mathematician and statician, and Egon Sharpe Pearson was a British statician. They co-invented and popularized the hypothesis testing techniques and the rejection and acceptance of the null hypothesis or the alternative hypothesis. 
:::

# The P-value and Hypothesis Test


## What is the P-value (P値とは)? {.smaller}

統計解析をすることで、P値を求めることは当たり前のようになりました。

$$
\text{P-value} = P(T(X) \ge T_0(X)|H_0)
$$


* 帰無仮説 $H_0$ にたいして、$T(X) > T_0(X)$ がおきる確率
* 帰無仮説に対して、収集したデータの整合性を指標科した値
* P値は 0 ~ 1 ($0 \leq \text{P-value} \leq 1$) の範囲をとる。
* 帰無仮説が正しいとき、P値は一様分布に従う。
* 帰無仮説が正しくとき：$\displaystyle \lim_{n \rightarrow \infty} P \rightarrow 0$。

::: {.notes}

- The P-value only makes sense when the null hypothesis is true. This is why we assume a true null, so that we can get a P-value.
- The original definition of the P-value: the chance of obtaining an effect equal to or more extreme than the one observed considering the null hypothesis is true.

**Links to StackExchange: Cross Validated Questions.**S

- [Intepretation of p-value in hypothesis testing.](https://stats.stackexchange.com/questions/46856/interpretation-of-p-value-in-hypothesis-testing)
- [What is the relationship between p values and type I errors](https://stats.stackexchange.com/questions/129628/what-is-the-relationship-between-p-values-and-type-i-errors)
- [How do I find the probability of type II errors](https://stats.stackexchange.com/questions/7402/how-do-i-find-the-probability-of-a-type-ii-error/7404)

:::

## 帰無仮説は正しいときのP値

```{r}
#| echo: false
#| warning: false
#| message: false
#| cache: true
#| fig-width: 4
#| fig-height: 2
#| fig-align: "center"

t_test = function(n = 10, mu = 50) {
  x1 = rnorm(n, mean = mu)
  x2 = rnorm(n, mean = mu)
  t.test(x1, x2, var.equal = TRUE)$p.value
  }

dset = tibble(p.value = replicate(10000, t_test())) 

ggplot(dset) +
  geom_histogram(aes(x = p.value), binwidth = 0.05,
                 boundary = 0.0) + 
  geom_vline(xintercept = 0.05, color = "orangered") +
  scale_x_continuous("P-values") + 
  scale_y_continuous("") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.title = element_blank(), 
        panel.grid = element_blank())
x = dset |> summarise(cnt = sum(p.value < 0.05) / length(p.value))
```

::: {style="font-size:50%;"}

帰無仮説が正しいとき $((\mu_0=50) = (\mu_A=50))$、
P値は一様分布に従います。
実験を10万回繰り返し実施たとき、 $P(\text{P-value}<0.05) = `r round(x, 4)`$でした。
:::

## 帰無仮説は正しくないときのP値

```{r}
#| echo: false
#| warning: false
#| message: false
#| cache: true
#| fig-width: 4
#| fig-height: 2
#| fig-align: "center"

t_test = function(n = 10, mu = 50) {
  x1 = rnorm(n, mean = mu)
  x2 = rnorm(n, mean = 51)
  t.test(x1, x2, var.equal = TRUE)$p.value
  }

dset = tibble(p.value = replicate(10000, t_test())) 

ggplot(dset) +
  geom_histogram(aes(x = p.value), binwidth = 0.05,
                 boundary = 0.0) + 
  geom_vline(xintercept = 0.05, color = "orangered") +
  scale_x_continuous("P-values") + 
  scale_y_continuous("") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.title = element_blank(), 
        panel.grid = element_blank())
x = dset |> summarise(cnt = sum(p.value < 0.05) / length(p.value))
```

::: {style="font-size:50%;"}
帰無仮説は正しくないとき $((\mu_0=50) \ne (\mu_A=51))$、
P値は一様分布に従いません。
実験を10万回繰り返し実施たとき、 $P(\text{P-value}<0.05) = `{r} round(x, 4)`$でした。
:::

## 仮説検定


**仮説検定は客観的に意思決定をするために使います。**

* P値は帰無仮説と対立仮説を比較するために使います。
* 帰無仮説を棄却するルールは有意水準を用いて行います。
* $\text{P-value} \leq \alpha$　のとき帰無仮説を棄却します。
* 帰無仮説を棄却・採択することで、誤りを起こすことになる
    - 第１種の誤り, α過誤 (Type-I error)
    - 第２種の誤り, β過誤 (Type-II error)

## 帰無仮説に注意

Neyman-Pearson の仮説検定法は **Null Hypothesis Significance Test (NHST) (帰無仮説の有意性検定)** といいます。
意思決定をするための手法なので、誤りを起こすこともある

* **Type-I Error (第１種の誤り):** 帰無仮説が正しいのに、帰無仮説を棄却する誤り。誤る確率は $\alpha$　（有意水準と同じ値）
* **Type-II Error (第２種の誤り):** 帰無仮説が正しくないのに、帰無仮説を棄却しない誤り。誤る確率は $\beta$（単純に求められない）

## 帰無仮説に注意

* $\alpha$ 有意水準および第1種の誤り
* $\beta$ 第2種の誤り
* $1-\beta$ 検定の検出力、正しくない帰無仮説を棄却する確率
* 第1種の誤りを厳しくすると、第2種の誤りはあまくなる (お互いに反比例する)

$$
\alpha \propto 1/\beta
$$


## 第１種と第２種の誤り

```{r}
#| echo: false
#| eval: true
A = c(0.05, 0.10)
B = c(0.36, 0.24)
c1 = 900 * A # 誤って棄却
c2 = 900 - c1 # 正しく棄却
c4 = 100 * B # 誤って棄却しない
c3 = 100 - c4 # 正しく棄却
rat = c3 / (c3+c1)
```

```{r}
#| echo: false
#| cache: false
#| fig-align: center

magick::image_read_pdf("~/Documents/QTIKZ/statchart.pdf") |> 
  magick::image_border(color = "white")

```


::: {.notes}

[Biau et al. 2010. Clin. Orthop. Relat. Res. 468: 885-892.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2816758/)

Fig. 2 of Biau et al. 2010 is wrong, since if the Type-I error rate decreases, then the Type-II error rate increases.

There is a false impression that if experiments are conducted with a low Type I error, then significant results almost always corresponds to a true effect. 

Out of 1000 null hypothesis, 10% are actually false. 
In otherwords, the null hypothesis is rarely false.
So, 900 are true null hypothesis and 100 are false null hypothesis.
However, we do not know this.
Suppose that we perform tests that have an α of 0.10 and a β of 0.24,
Among the true null hypothesis, since our Type-I error rate is 0.10, then 90 experiments will be erroneously rejected.
Among the false null hypothesis, since our Type-II error rate is 0.24, then 24 experiments will be
erroneously not rejected and 80 will be correctly rejected.

Therefore, a total of 90+76 null hypotheses will be rejected, but only 76 / (90+76) = 0.46 of these were correctly rejected.

**I am not sure if this is a good example, since the null hypothesis is only rare false. What is the point of this?**

:::

## 有意性検定と仮説検定の違い {.smaller}

:::: {.columns}
::: {.column width="50%"}

**Significance testing (有意性検定)**

* Fisher の手法
* P値の値は重要
* 帰無仮説を棄却するために使う
* データを見てから計算する
* 解析したデータのみに有効
* Subjective decision (主観的な判断)
* エビデンスによる意思決定

:::
::: {.column width="50%"}

**NHST (仮説検定)**

* Neyman and Pearson の手法
* 第1種の誤りが重要
* 第1種と第2種の誤りを最低限にする
* データを見てから、α と β を選ぶ
* 実験は十分に反復されており、今後も似たようなデータを期待できる
* Objective decision (客観的)
* ルールに基づいた意思決定

:::
::::

::: {.notes}

- [Biau et al. 2010. Clin. Orthop. Relat. Res. 468: 885-892.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2816758/)

See Fig. 1A-B in this paper. Since Fisher's P-value is valid for each experiment
individually, some experiments will provide evidence for rejecting the null and some won't.

- The p value is not the probability of the null hypothesis being true; it is the probability of observing these data, or more extreme data, if the null is true.
- However, for Neyman-Pearson method, there is only a chance of making an error of rejecting or accepting a hypothesis based on an α and β value.

:::


# Introduction to the Null Hypothesis Significance Test (NHST)


## Example {.smaller}

:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: false
set.seed(2020)
data = tibble(experiment = LETTERS[1:2]) |> 
  mutate(data = map(experiment, function(x) {
    mu = ifelse(x == "A", 10, 12)
    tibble(observation = rnorm(20, 10))
  })) |> 
  unnest(data)
data |> 
  ggplot(aes(x = experiment, y = observation)) + 
  geom_boxplot(width = 0.5) +
  geom_point(position = position_jitter(0.1), color = "orangered") 
```
:::

::: {.column width="50%"}


```{r}
out = t.test(observation ~ experiment, data = data)
t.test(observation ~ experiment, data = data)
```

:::
::::

::: {style="font-size:50%;"}
* $H_0: \overline{\mu_A}=\overline{\mu_B}~:\text{Null hypothesis}$
* $H_1: \overline{\mu_A}\neq\overline{\mu_B}~:\text{Alternative hypothesis}$
* True standard deviation：$\sigma_A=\sigma_B$
* True mean: $\overline{\mu_A}=10$ and $\overline{\mu_B}=12$
* In this case, $P = `r round(out$p.value, 4)`  \nless \alpha = 0.05$
:::

::: {.notes}
The true means are different, yet the P-value for the Welch's two sample t-test is greater than 0.05.
What does this mean?

Do we accept the alternative hypothesis?

Do we reject the null hypothesis?
:::

## Amerhein et al. 2019. Nature 567: 305-307 {.smaller}

:::: {.columns}
::: {.column width="50%"}


> Let's be clear about what must stop: we should never conclude there is 'no difference' or 'no association' just because a P-value is larger than a threshold such as 0.05 ... --Amerhein et al. 2019

:::
::: {.column width="50%"}

```{r}

#| echo: false
set.seed(2020)
data = 
  tibble(experiment = LETTERS[1:2],
         n = c(200, 200),
         sd = c(1, 2)) |> 
  mutate(data = map2(n, sd, function(n, sd) {
    tibble(observation = rnorm(n, 10, sd)) |> 
      mutate(observation = scale(observation, scale=F)[,1] + 10)
  })) |> 
  unnest(data)

data2 = data |> group_by(experiment) |> 
  summarise(ymin = min(observation),
            ymax = max(observation),
            y25 = quantile(observation, 0.25),
            y50 = quantile(observation, 0.50),
            y75 = quantile(observation, 0.75))

data |> 
  ggplot() + 
  geom_boxplot(aes(x = experiment,
                   ymin = ymin, ymax = ymax, middle = y50,
                   lower = y25, upper = y75), 
               stat = "identity",
               width = 0.5,
               data = data2) +
  geom_point(aes(x = experiment, y = observation),
             position = position_jitter(0.1), color = "orangered",
             data = data)  +
  geom_hline(aes(yintercept = 6)) +
  scale_x_discrete("", labels = c("Technician A", "Technician B")) +
  scale_y_continuous("Decreasing effect ⬅　Effect　➡ Increasing effect") +
  coord_flip()

```
:::
::::

P値は 0.05 より大きい場合、「違いはない」、「実験の影響はない」、
「関係性はない」のような解釈は誤りです。

$P>0.05$ は、帰無仮説を棄却するほどの情報量がないだけを意味します。
決定的に実験の効果がないまでは言えませんが、効果がなかったことについては丁寧に考察する必要はあるでしょう。
帰無仮説を棄却したときも同じように疑いながら結果の考察は重要です。
たまたま棄却できたときもあります（第２種誤り）。


