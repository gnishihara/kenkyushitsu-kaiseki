---
title: "Comparing multiple groups"
subtitle: 分散分析の紹介
author: Greg Nishihara
date: today
format: 
 revealjs:
   df-print: paged
fig-align: center
fig-width: 8
execute: 
  cache: true
---


```{r}
library(tidyverse)
library(ggrepel)
library(Hmisc)
library(kableExtra)
library(knitr)
library(tikzDevice)
library(patchwork)
library(knitr)
library(kableExtra)
library(furrr)
plan("multisession")

set.seed(2019)
options(knitr.kable.NA = "")
```

# Problems with multiple comparisons

## アマモの全長の比較

3つの沿岸域（A, B, and C）のアマモ (*Zostera marina*) を採取しました。
作業仮説は「アマモの全長は沿岸域によって，長さがことなる」です。

```{r}
#| fig-width: 8
#| fig-height: 4
set.seed(2019)
mu = c(35, 40, 38)
N = c(10,10,10)
CV = c(0.10, 0.10, 0.10)
sd = mu * CV

X = 
  tibble(mu, sd, N, site = LETTERS[1:3]) %>% 
  mutate(data = pmap(list(mu,sd,N), function(mu, sd, N) rnorm(N, 0,sd)+mu)) %>% 
  unnest(data) %>% 
  mutate(site = as.factor(site))

ggplot(X) +
  geom_point(aes(x = site, y=data, color = site), position=position_jitter(0.1), size = 3) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)") +
  guides(color=F)
```



## t検定で比較する {.scrollable}

3 カ所の全長を比較するのであれば，次のような組み合わせを考えられます。

* A -- B
* A -- C
* B -- C

t 検定を 3 回実行して，比較してみたら，結果は次の通りです。

```{r}
dataA = X %>% filter(site == "A")
dataB = X %>% filter(site == "B")
dataC = X %>% filter(site == "C")
tAB = t.test(dataA$data, dataB$data)
tAC = t.test(dataA$data, dataC$data)
tBC = t.test(dataB$data, dataC$data)
```

```{r}
#| echo: false
#| eval: true
tibble(
  Test = c("A-B", "A-C", "B-C"),
  `t-value` = c(tAB$statistic, tAC$statistic, tBC$statistic),
  `d.f.` = c(tAB$parameter, tAC$parameter, tBC$parameter),
  `p-value` = c(tAB$p.value, tAC$p.value, tBC$p.value)) %>% 
  knitr::kable(digits = c(NA, 3,3,4))
```


NHST （帰無仮説の有意性検定）によると，A--B と A--C の帰無仮説は棄却できますが，B--C の帰無仮説の棄却はできません。

## 多重仮説検定の問題 {.smaller}

$\alpha$ は有意水準ですが，第 1 種の誤りを起こす確率でもあります。つまり，$\alpha$ は帰無仮説が正しくても誤って棄却する確率です。

アマモの全長の解析には，t 検定を 3 回しました。1 回の検定にかかる第 1 種の誤りは 0.05 でしたが，3 回も検定したので（多重仮説検定），全体の第 1 種の誤りを起こす確率は次の通りです。

$$
α_{all}=1-(1-α)_{\text{A-B}}(1-α)_{\text{A-C}}(1-α)_{\text{B-C}} = 1-0.95^3 = 0.1426
$$

## 多重仮説検定したときの α 過誤


::::{.columns}
:::{.column width="0.5"}

多重仮説検定をするときに，全ての仮説の中から少なくとも 1 つの正しい帰無仮説が誤って棄却されてしまう確率が $\alpha_{\text{fwer}}$ です。

$$
\alpha_{\text{fwer}} = 1 - (1-\alpha)^n
$$

全体の $\alpha$ 過誤をおさえたければ，各実験の $\alpha$ を抑えれことが必要です。

:::
:::{.column width="0.5"}

```{r}
#| fig-width: 4
#| fig-height: 4
alphafun = function(x, alpha) {1 - (1-alpha)^x}
tibble(alpha = c(0.01, 0.05, 0.1), n = 1:3) %>% 
  complete(alpha, n = seq(1, 10, by = 0.1)) %>% 
  mutate(afwer = alphafun(n, alpha)) %>% 
  ggplot(aes(x = n, y = afwer, color = as.factor(alpha))) + 
  geom_line(size = 2) + 
  scale_x_continuous("比較する数", breaks = 1:10) +
  scale_y_continuous(parse(text = "'全体の'*alpha['fwer']")) +
  scale_color_viridis_d(parse(text = "'実験ごとの'*alpha"), end = 0.8) +
  theme(legend.background=element_blank(),
        legend.position=c(0,1),
        legend.justification=c(0,1))
```

:::
::::

 fwer: family-wise error rate （ファミリーワイズエラー率）

# Analysis of Variance

## 一元配置分散分析



**一元配置分散分析 (One-way ANOVA)** は， 1つの要因（因子, factor）A の複数の水準（群, group, level） A~1~, A~2~, ..., A~p~ にたいして，各水準の母平均の差を検証するための検定です。

:::{.absolute top=400}

**帰無仮説: $\mu_1 = \mu_2 = \cdots = \mu_p$**

全水準の平均値は等しい
:::

## 一元配置分散分析

解析に使うモデルの次の方程式で定義します。


$$
x_{ij} = \mu + \alpha_i + \epsilon_{ij}
$$

$\mu$ は総平均値，$x_{ij}$ は水準 $i$ の指数 $j$ の観測値です。$\alpha_i$ は$\mu$ に対する水準 $i$ の効果です。$\epsilon_{ij}$ はお互いに独立に正規分布 $(N(0, \sigma^2))$ に従う誤差項です。ただし，$\sum_{i=1}^n \alpha_i = 0$ とします。**このとき，帰無仮説は $\alpha_1 = \alpha_2 = \cdots = \alpha_n$ です。**

::: aside
このときの α は有意水準ではない。
:::

## 一元配置分散分析表 {.smaller}


```{r}
#| echo: false
#| results: asis

tble = tibble(要因 = c("A", "e", " "),
      `自由度 (df)` = c("$df_A = I-1$", "$df_R = I(J-1)$", "$df_T =IJ-1$"),
      `平方和 (SS)` = c("$SS_A$", "$SS_R$", "$SS_T$"),
      `平均平方 (MS)` = c("$MS_A = SS_A / df_A$",
                            "$MS_R = SS_R / df_R$",
                            " "),
      `F値` = c("$MS_A / MS_R$", " ", " "),
      `P値` = c("$qf(1-α, df_A, df_R)$", "", "")) %>% 
  kable(escape=FALSE) |> 
  kable_styling(font_size = 20)
cat(tble)
```

$A$ は要因, $e$ は残渣（誤差項）,$I$ は水準の数,  $J$ は標本の数です。$SS_A$ は水準間平方和，$SS_R$ は残渣平方和, $SS_T$は総平方和です。$MS_A$ は水準間平均平方，$MS_R$ は残渣平均平方です。F値は平均平方の比です。水準間の平均値に対して，誤差（ばらつき，残渣）が大きいと，残渣平均平方も大きくなります。F値の分母が分子より大きくなったら，帰無仮説を棄却しにくくなります。

## 平方和の方程式


$$
\underbrace{\sum_{i=1}^I\sum_{j=1}^J(x_{ij} - \overline{\overline{x}})^2 }_{\text{総平方和}\;(SS_T)} =
\overbrace{J\sum_{i=1}^I(\overline{x}_{i}+\overline{\overline{x}})^2}^{\text{水準間平方和}\;SS_A} +
\underbrace{\sum_{i=1}^I\sum_{j=1}^J(x_{ij} - \overline{x}_i)^2}_{\text{残渣平方和}\;SS_R}
$$

$\bar{x}_i$ は標本平均，$\bar{\bar{x}}$ は総平均です。

## 平均方和を分解すると {.smaller}

```{r}
#| fig-width: 8
#| fig-height: 4
out = lm(data ~ site, X)
xmean = X %>% pull(data) %>% mean()
X = X %>% 
  mutate(predict = predict(out),
         residuals = residuals(out))
Z = X %>% select(site, predict) %>% distinct() %>% 
  mutate(xmean = xmean, 
         residuals =  predict - xmean)

p1 = ggplot(X) +
  geom_pointrange(aes(x= site, xend = site, 
                      y = data,
                      ymin = data, 
                      ymax = data - residuals, color = site), 
                  position=position_jitter(0.2)) +
  geom_errorbar(aes(x = site, y = predict, ymin = predict, ymax = predict),
                color = "black",
                data = X %>% select(site, predict) %>% distinct()) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)", limits = c(25, 50)) +
  ggtitle("Siteごとの平均値と残渣") +
  guides(color = F)


p2 = ggplot(Z) +
  geom_pointrange(aes(x= site, 
                      y = predict,
                      ymin = predict, 
                      ymax = predict - residuals, color = site)) + 
  geom_hline(yintercept = xmean) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)", limits = c(30, 40)) +
  ggtitle("総平均とsiteごと効果") +
  guides(color = F)  

p1 + p2
```


残渣平均平方は Field site (`site` 変数) ごとの残渣に影響されます。残渣のばらつきが小さいほど，残渣平均平方が小さくなります。
総平均に対する Field site の効果が大きければ，水準間平均平方が大きくなります。

:::{notes}
The simulated data case, where the MS of the site is larger than the MS of the residuals.
:::

## 平均方和: 水準ごとのばらつきが小さいとき {.smaller}


```{r}
#| fig-width: 8
#| fig-height: 3
X1 = X %>% group_by(site) %>% 
  nest() %>% 
  mutate(data = map(data, function(x) {
    z = mean(x$data)
    s = sd(x$data)
    z1 = scale(x$data)[,1]
    z1 * 0.5*s  + z
  })) %>% unnest(data)

out = lm(data ~ site, X1)
xmean = X1 %>% pull(data) %>% mean()
X1 = X1 %>% ungroup() %>% 
  mutate(predict = predict(out),
         residuals = residuals(out))
Z = X1 %>% select(site, predict) %>% distinct() %>% 
  mutate(xmean = xmean, 
         residuals =  predict - xmean)

p1 = ggplot(X1) +
  geom_pointrange(aes(x= site, 
                      y = data,
                      ymin = data, 
                      ymax = data - residuals, color = site), 
                  position=position_jitter(0.2)) +
  geom_errorbar(aes(x = site, y = predict, ymin = predict, ymax = predict),
                color = "black",
                data = X1 %>% select(site, predict) %>% distinct()) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)", limits = c(30, 45)) +
  ggtitle("Siteごとの平均値と残渣") +
  guides(color = F)

p2 = ggplot(Z) +
  geom_pointrange(aes(x= site, 
                      y = predict,
                      ymin = predict, 
                      ymax = predict - residuals, color = site)) + 
  geom_hline(yintercept = xmean) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)", limits = c(30, 40)) +
  ggtitle("総平均とsiteごと効果") +
  guides(color = F)  
p1 + p2
```


水準間平均平方 (`site: Mean Sq`) はかわらないが，残渣平均平方 (`Residuals: Mean Sq`) は小さくなった。


```{r}
anova(out)
```

:::{.notes}
* The same data but the variation within the sites are made smaller.
* The variation among sites are not changes.
* In this case, the MS of the residuals decrease.
:::

## 平均方和: 水準ごとのばらつきが大きいとき {.smaller}

水準間平均平方 (`site: Mean Sq`) はかわらないが，残渣平均平方 (`Residuals: Mean Sq`) は大きくなった。

```{r}
X1 = X %>% group_by(site) %>% 
  nest() %>% 
  mutate(data = map(data, function(x) {
    z = mean(x$data)
    s = sd(x$data)
    z1 = scale(x$data)[,1]
    z1 * 1.5*s  + z
  })) %>% unnest(data)

out = lm(data ~ site, X1)
xmean = X1 %>% pull(data) %>% mean()
X1 = X1 %>%  ungroup() %>% 
  mutate(predict = predict(out),
         residuals = residuals(out))
Z = X1 %>% select(site, predict) %>% distinct() %>% 
  mutate(xmean = xmean, 
         residuals =  predict - xmean)

anova(out)
```


```{r}
#| fig-width: 8
#| fig-height: 3
p1 = ggplot(X1) +
  geom_pointrange(aes(x= site, xend = site, 
                      y = data,
                      ymin = data, 
                      ymax = data - residuals, color = site), 
                  position=position_jitter(0.2)) +
  geom_errorbar(aes(x = site, y = predict, ymin = predict, ymax = predict),
                color = "black",
                data = X1 %>% select(site, predict) %>% distinct()) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)", limits = c(25, 50)) +
  ggtitle("Siteごとの平均値と残渣") +
  guides(color = F)

p2 = ggplot(Z) +
  geom_pointrange(aes(x= site, 
                      y = predict,
                      ymin = predict, 
                      ymax = predict - residuals, color = site)) + 
  geom_hline(yintercept = xmean) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (cm)", limits = c(30, 40)) +
  ggtitle("総平均とsiteごと効果") +
  guides(color = F)  
p1+p2
```

:::{.notes}
* The same data but the variation within the sites are made larger.
* The variation among sites are not changes.
* In this case, the MS of the residuals increase, because the noise is larger in the residuals.
:::

## 分散分析の統計量

分散分析で求める統計量は F値 とよびます。

$$
F = \left . \frac{SS_A}{I-1} \right / \frac{SS_R}{I(J-1)}  = \frac{MS_A}{MS_R}
$$

F値は自由度 $I-1, I(J-1)$ のF分布に従います。

## F値の確率密度関数 {.smaller}

$$
P(x|d_1, d_2) = \frac{1}{\mathrm{B}\left(\frac{d_1}{2}, \frac{d_2}{2}\right)}\left(\frac{d_1}{d_2}\right)^{\left(\frac{d_1}{2}\right)}x^{\left(\frac{d_1}{2}-1\right)}\left(1+\frac{d_1}{d_2}x\right)^{\left(-\frac{d_1+d_2}{2}\right)}
$$


$\mathrm{B}(d_1, d_2)=\int_0^1t^{x-1}(1-t)^{y-1}dt$ はベータ関数，$d_1$ と $d_2$ は正数です。$x$ が確率変数です。


```{r}
#| fig-width: 8
#| fig-height: 3
Z= tibble(df1 = c(1, 2, 5, 10, 90), 
         df2 = c(1, 1, 1,  5, 90)) %>% 
  mutate(data = map2(df1,df2, function(x,y) {
    fval = seq(0, 5, by = 0.01)
    tibble(fval = fval,
           pval = df(fval, x,y))
  })) %>% 
  # mutate(group = paste0("list(d[1] ==", df1, ", d[2] == ", df2, ")") ) %>% 
  mutate(group = str_glue("d[1] == {df1}*','~ d[2] == {df2}")) %>% 
  unnest(data) 

ggplot(Z) +
  geom_line(aes(x = fval, y = pval, color = group)) +
  scale_color_viridis_d(labels = parse(text = unique(Z$group)), end = 0.8)+
  scale_x_continuous("F-value") +
  scale_y_continuous(limits=c(0, 2))+
  theme(legend.text.align=0,
        legend.background=element_blank(),
        legend.title=element_blank(),
        legend.position=c(1,1),
        legend.justification=c(1,1),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y=element_blank())

```


## 一元配置分散分析の仮定

分散分析に次の仮定が定義されています。

* 母集団の分散は等しい
* 残渣は正規分布する
* 任意の水準の応答（応答変数，説明したいデータ，y軸の値）はお互いに独立で同一の分布に従う正規確率変数であること


## アマモの全長の解析 {.scrollable}

Rでは，いろんな方法で分散分析ができます。


```{r}
#| echo: true
aov(data ~ site, data = X) %>% summary()
```

```{r}
#| echo: true
lm(data ~ site, X) %>% summary.aov()
```

実は，`oneway.test()`, `aov()`, と `lm()`  関数で分散分析ができます。
不等分散のとき，`oneway.test()` はウェルチの分散分析を実行してくれますが，一般的につかわれていません。
さらに，`oneway.test()` の結果から解析の診断や多重仮説検定を簡単にできません。
`aov()` は `lm()` ラッパー (wrapper) なので，`aov()` を実行したとき，裏で `lm()` が実行されます。



# Type-I error, Type-II error, violation of assumptions

## α過誤，β過誤，検出力 {.scrollable}

::::{.columns}
:::{.column width="0.5"}
```{r}
#| eval: false
#| echo: true
library(pwr)
J = 3 # 群の数
effect_size = 1 # 効果
MSR = 1 # 残渣平均平方
power = 0.80 # 検出力
alpha = 0.05 # 有意水準・α過誤
lambda = effect_size / MSR 
pwr.anova.test(k = J, 
               f = lambda, 
               power = power) # pwr パッケージの関数
```
:::
:::{.column width="0.5"}

```{r}
#| echo: false
library(pwr)
J = 3 # 群の数
effect_size = 1 # 効果
MSR = 1 # 残渣平均平方
power = 0.80 # 検出力
alpha = 0.05 # 有意水準・α過誤
lambda = effect_size / MSR 
x = pwr.anova.test(k = J, f = lambda, power = power) # pwr パッケージの関数
N = x$n
x
```
:::
::::

一元配置分散分析の検出力は 0.80，$\alpha$ は 0.05，
水準の数は 3，標本平均の最小と最大の差（効果）は 1，
残渣平均平方と効果の比を 1 にしたとき，各群の標本数を求めました。
このときの効果は 1 としましたが，`lambda` ($\lambda$) の方程式は次のとおりです。

$$
\lambda = \frac{\sum_{j-1}^Jn\beta_j}{\sigma_e^2}
$$
$\beta_j$ は $j$ 水準の効果，$n$ は $j$ 群の標本数，$\sigma_e^2$ は母分散です。
$n$, $\beta_j$, $\sigma_e^2$ は未知なので，客観的に選ぶ必要があります。

必要な標本数は n = $`r round(N, 2)` \rightarrow `r as.integer(ceiling(N))`$ でした。

::: {.notes}
When the null hypothesis is TRUE, then the F-value follows a central F-distribution.
When the null hypothesis is FALSE, then the F-value follows a non-central F-distribution. 
This requires determining the non-centrality parameter (ncp).

$$
\displaystyle 
\lambda = \frac{\sum_{j-1}^Jn\beta_j}{\sigma_e^2}
$$

where $\beta$ is the effect size (difference between the group mean and the grand mean),
$n$ is the number of samples in group $j$, and $\sigma_e^2$ is population variance.

[https://stats.idre.ucla.edu/r/dae/one-way-anova-power-analysis/](UCLA: ONE-WAY ANOVA POWER ANALYSIS | R DATA ANALYSIS EXAMPLES)

[https://rpubs.com/davidtnly/411707](Rpub Document on power)

[http://users.stat.umn.edu/~corbett/classes/5303/ANOVA_power_handout.pdf](UMN PDF on power analysis)

Cohen's f^2^ is just the VAR(A) / VAR(R)
:::


## 分散分析のP値も一様分布する

帰無仮説が正しいとき，分散分析のP値は一様分布します。
シミュレーションの水準数は 3，各水準の標本数は 10，等分散には従っています。
```{r}
#| cache: true
#| 
makedata = function(n1=10,n2=10,n3=10,m1=20,m2=26,m3=23,s1=3,s2=3,s3=3) {
  
  tibble(factor = LETTERS[c(rep(1, n1), 
                            rep(2, n2),
                            rep(3, n3))]) %>% 
    mutate(value = c(rnorm(n1, m1, s1),
                     rnorm(n2, m2, s2),
                     rnorm(n3, m3, s3)))
}

runtest = function(N) {
  tibble(n1 = 10, n2= 10, n3 = 10, m1 = 20, m2 = 20, m3 = 20) %>% 
    complete(n1 = c(10, 10, 10),
             n2 = c(10, 10, 10),
             n3 = c(10, 10, 10),
             m1 = 20, 
             m2 = 20,
             m3 = 20) %>% 
    mutate(data = pmap(list(n1,n2,n3,m1,m2,m3), makedata)) %>% 
    mutate(pvalue = map_dbl(data, function(X) {
      x = aov(value ~ factor, X) %>% summary() 
      x[[1]]$`Pr(>F)`[1]
    })) %>% select(-data) 
}
out = tibble(N = 1:5000) %>% 
  mutate(result = future_map(N, runtest))
```

```{r}
#| fig-width: 8
#| fig-height: 4
out %>% unnest(result) %>% 
  mutate(group = interaction(n1,n2,n3)) %>% 
  ggplot(aes(x = pvalue)) +
  geom_histogram(breaks = seq(0, 1, by = 0.05)) +
  geom_vline(xintercept=0.05, color = "orangered") +
  scale_x_continuous("P-value")+
  theme(axis.line.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.title.y=element_blank())

```

## 不等分散のときα過誤は少々あがる(N=10)  {.smaller}

::: {.panel-tabset}

### 説明

帰無仮説が正しいとき，そして等分散性が守られていないとき，P値は一様分布しません。
それにして，帰無仮説を棄却しやすくなりません。
実施される F 検定は保守的なので，どちらかというと，有意な結果はでません。
つまり，第１種の過誤を起こす確率はあまりあがりません。
`20・30・30` や `10・10・30` は水準間の平均値に対する分散の％割合を示しています。
等分散の群は `Control` です。このときの標本数は10, 水準数は 3 です。

### 図

```{r}
#| cache: true
#| echo: false
set.seed(2019)
makedata = function(n1=10,n2=10,n3=10,m1=20,m2=20,m3=20,cv1=1,cv2=1,cv3=1) {
  
  tibble(factor = LETTERS[c(rep(1, n1), 
                            rep(2, n2),
                            rep(3, n3))]) %>% 
    mutate(value = c(rnorm(n1, m1, m1*cv1),
                     rnorm(n2, m2, m2*cv2),
                     rnorm(n3, m3, m3*cv3)))
}

runtest = function(N) {
  tibble(n1 = 10, n2 = 10, n3 = 10, 
         cv1 = 0.1, cv2 = 0.2, cv3 = 0.2) %>% 
    complete(n1 = c(10),
             n2 = c(10),
             n3 = c(10),
             cv1 = c(0.1,0.2,0.3), 
             cv2 = c(0.1,0.2,0.3),
             cv3 = c(0.1,0.2,0.3)) %>% 
    mutate(data = pmap(list(n1=n1,n2=n2,n3=n3,
                            cv1=cv1,cv2=cv2,cv3=cv3), makedata)) %>% 
    mutate(pvalue = map_dbl(data, function(X) {
      x = aov(value ~ factor, X) %>% summary() 
      x[[1]]$`Pr(>F)`[1]
    })) %>% select(-data) 
}

out = tibble(N = 1:1000) %>% mutate(result = future_map(N, runtest))
```

```{r}
#| fig-width: 8
#| fig-height: 4

out %>% unnest(result) %>% 
  select(cv1,cv2,cv3,pvalue) %>% 
  group_by(cv1, cv2, cv3) %>% 
  summarise(S = sum(pvalue <= 0.05)/length(pvalue)) %>% 
  mutate(group = pmap_chr(list(cv1, cv2, cv3), function(x,y,z) {
    Z = 100*c(x,y,z) %>% sort() 
    paste(Z, collapse="・")
  }))  %>% 
  mutate(group2 = ifelse(group %in% c("10・10・10", 
                                    "20・20・20", 
                                    "30・30・30"), 
                        "Equal variance", "Unequal variance")) %>% 
  group_by(group) %>% 
  mutate(meanpvalue = mean(S)) %>% 
  arrange(meanpvalue) %>% 
  ggplot() +
  geom_point(aes(x = reorder(group, meanpvalue), y = S,
                 color = group2),
             position = position_jitter(0.2))  +
  # geom_col(aes(x = reorder(group, pvalue), y = pvalue))  +
  geom_hline(yintercept=0.05, color = "orangered") +
  scale_y_continuous("P(P-value < 0.05)", limits = c(NA, 0.1)) +
  scale_x_discrete("Differences in standard deviation (A・B・C)") +
  scale_color_viridis_d(end = 0.8) +
  theme(legend.position = "top", legend.title = element_blank())
```

:::

## 標本数をあげればα過誤は若干さがる(N=100) {.smaller}

::: {.panel-tabset}

### 説明

帰無仮説が正しいとき，標本数を100 にしたら第１種の過誤を起こす確率は若干さがります。
`20・30・30` や `10・10・30` は水準間の平均値に対する分散の％割合を示しています。
等分散の群は `Control` です。

### 図

```{r}
#| cache: true
#| echo: false
set.seed(2019)
makedata = function(n1=10,n2=10,n3=10,
                    m1=20,m2=20,m3=20,
                    cv1=1,cv2=1,cv3=1) {
  
  tibble(factor = LETTERS[c(rep(1, n1), 
                            rep(2, n2),
                            rep(3, n3))]) %>% 
    mutate(value = c(rnorm(n1, m1, m1*cv1),
                     rnorm(n2, m2, m2*cv2),
                     rnorm(n3, m3, m3*cv3)))
}

runtest = function(N) {
  tibble(n1 = 10, n2= 10, n3 = 10, 
         cv1 = 0.1, cv2 = 0.2, cv3 = 0.2) %>% 
    complete(n1 = c(100),
             n2 = c(100),
             n3 = c(100),
             cv1 = c(0.1,0.2,0.3), 
             cv2 = c(0.1,0.2,0.3),
             cv3 = c(0.1,0.2,0.3)) %>% 
    mutate(data = pmap(list(n1=n1,n2=n2,n3=n3,
                            cv1=cv1,cv2=cv2,cv3=cv3), makedata)) %>% 
    mutate(pvalue = map_dbl(data, function(X) {
      x = aov(value ~ factor, X) %>% summary() 
      x[[1]]$`Pr(>F)`[1]
    })) %>% select(-data) 
}

out = tibble(N = 1:1000) %>% mutate(result = future_map(N, runtest))

```

```{r}
#| fig-width: 8
#| fig-height: 4
out %>% unnest(result) %>% 
  select(cv1,cv2,cv3,pvalue) %>% 
  group_by(cv1, cv2, cv3) %>% 
  summarise(S = sum(pvalue <= 0.05)/length(pvalue)) %>% 
  mutate(group = pmap_chr(list(cv1, cv2, cv3), function(x,y,z) {
    Z = 100*c(x,y,z) %>% sort() 
    paste(Z, collapse="・")
  }))  %>% 
  # mutate(group = ifelse(group %in% c("10・10・10", 
  #                                    "20・20・20", 
  #                                    "30・30・30"), "Control", group)) %>% 
  mutate(group2 = ifelse(group %in% c("10・10・10", 
                                    "20・20・20", 
                                    "30・30・30"), 
                        "Equal variance", "Unequal variance")) %>% 
  group_by(group) %>% 
  mutate(meanpvalue = mean(S)) %>% 
  arrange(meanpvalue) %>% 
  ggplot() +
  geom_point(aes(x = reorder(group, meanpvalue), y = S,
                 color = group2),
             position = position_jitter(0.2))  +
  # geom_col(aes(x = reorder(group, pvalue), y = pvalue))  +
  geom_hline(yintercept=0.05, color = "orangered") +
  scale_y_continuous("P(P-value < 0.05)", limits = c(NA, 0.08)) +
  scale_x_discrete("Differences in standard deviation (A・B・C)") +
  scale_color_viridis_d(end = 0.8) +
  theme(legend.position = "top", legend.title = element_blank())

```

:::

## 不等分散のときβ過誤はあがる(N=10) {.smaller}

::: {.panel-tabset}

### 説明


帰無仮説が正しくないとき，さらに
等分散性が守られていないとき，正しく帰無仮説を棄却しにくくなります。
第2種の過誤が起きやすくなります。
`20・30・30` や `10・10・30` は水準間の平均値に対する分散の％割合を示しています。
等分散の群は `Control` です。

### 図

```{r}
#| cache: true
#| echo: false
set.seed(2019)
makedata = function(n1=10,n2=10,n3=10,m1=10,m2=15,m3=20,cv1=0.1,cv2=0.1,cv3=0.1) {
  
  tibble(factor = LETTERS[c(rep(1, n1), 
                            rep(2, n2),
                            rep(3, n3))]) %>% 
    mutate(value = c(rnorm(n1, m1, m1*cv1),
                     rnorm(n2, m2, m2*cv2),
                     rnorm(n3, m3, m3*cv3)))
}

runtest = function(N) {
  tibble(m1 = 10, m2= 10, m3 = 10, 
         cv1 = 0.1, cv2 = 0.2, cv3 = 0.2) %>% 
    complete(m1 = c(100),
             m2 = c(120),
             m3 = c(140),
             cv1 = c(1,2,3)/10, 
             cv2 = c(1,2,3)/10,
             cv3 = c(1,2,3)/10) %>% 
    mutate(data = pmap(list(m1=m1, m2=m2, m3=m3,
                            cv1=cv1,cv2=cv2,cv3=cv3), makedata)) %>% 
    mutate(pvalue = map_dbl(data, function(X) {
      x = aov(value ~ factor, X) %>% summary() 
      x[[1]]$`Pr(>F)`[1]
    })) %>% select(-data) 
}
out = tibble(N = 1:1000) %>% mutate(result = future_map(N, runtest))
```

```{r}
#| fig-width: 8
#| fig-height: 4
out %>% unnest(result) %>% 
  select(cv1,cv2,cv3,pvalue) %>% 
  group_by(cv1, cv2, cv3) %>% 
  summarise(S = sum(pvalue >= 0.05)/length(pvalue)) %>% 
  mutate(group = pmap_chr(list(cv1, cv2, cv3), function(x,y,z) {
    Z = 100*c(x,y,z) %>% sort() 
    paste(Z, collapse="・")
  }))  %>% 
  # mutate(group = ifelse(group %in% c("10・10・10", 
  #                                    "20・20・20", 
  #                                    "30・30・30"), "Control", group)) %>%
  mutate(group2 = ifelse(group %in% c("10・10・10", 
                                    "20・20・20", 
                                    "30・30・30"), 
                        "Equal variance", 
                        "Unequal variance")) %>% 
  group_by(group) %>% 
  mutate(meanpvalue = mean(S)) %>% 
  arrange(meanpvalue) %>% 
  ggplot() +
  geom_point(aes(x = reorder(group, meanpvalue), y = S,
                 color = group2),
             position = position_jitter(0.2))  +
  # geom_col(aes(x = reorder(group, pvalue), y = pvalue))  +
  geom_hline(yintercept=0.05, color = "orangered") +
  scale_y_continuous("P(P-value < 0.05)", limits = c(NA, 1.00)) +
  scale_x_discrete("Differences in standard deviation (A・B・C)") +
  scale_color_viridis_d(end = 0.8) +
  theme(legend.position = "top", legend.title = element_blank())

```

:::

# ANOVA procedure

## 分散分析の手順 {.scrollable}

0. 作業仮説，帰無仮説，対立仮説をたてる。
1. 実験をデザインして，実行する。
2. 集めたデータの箱ヒゲ図を作図する。
    * 不等分散性が気になるなら，等分散性の検定を行なう。
    * Bartlett's test バートレット検定 (`bartlett.test()`)
    * Levene's test ルビーン検定 (`car` パケージに `leveneTest()` があります。)
    * Hartley's test ハートリー検定
    * BrownForsythe test
    * Fisher Ratio
    * Conover test
3. 分散分析を実施する。
4. 図を用いて残渣の正規性と等分散性を確認する。
5. 問題なければ，結果を報告する。問題があったとき，さらにデータ処理を行い，再び分散分析をする。

:::{.notes}
[https://stats.stackexchange.com/questions/135232/bartletts-test-vs-levenes-test](Cross Validated Link: Bartlett's test vs Levene's test)
:::

## 0. 作業仮説・帰無仮説・対立仮説の設定

最初の紹介した海域ごとのアマモの全長を解析します。

**作業仮説：** アマモの全長は沿岸域によって，長さがことなる

**帰無仮説：** アマモの海域ごとの全長は等しい $(\mu_A = \mu_B = \mu_C)$

**対立仮説：** 一つ以上のアマモの海域ごとの全長は異なる $(\mu_A \neq \mu_B |\mu_A \neq \mu_C|\mu_B \neq \mu_C)$

## 1. 実験をデザインして実行する


2019年3月1日に沿岸A，沿岸B，沿岸Cにおいて，各沿岸域から無作為に 10 個体のアマモを採取して，定規で全長を測定した。

帰無仮説を検証するために，一元配置分差分析を実施する。

## 2. 集めたデータの箱ヒゲ図


データ数が少ないのとき，散布図でも問題ないです。

```{r}
#| fig-width: 8
#| fig-height: 4
ggplot(X) +
  geom_boxplot(aes(x = site, y = data, fill = site)) +
  geom_point(aes(x = site, y = data),
             position = position_jitter(0.05)) +
  scale_x_discrete("Field site") +
  scale_y_continuous("Length (mm)") +
  theme(legend.position=c(0,1),
        legend.justification=c(0,1),
        legend.title=element_blank())
```

```{r}
#| eval: false
#| echo: true
ggplot(X) + geom_boxplot(aes(x = site, y = data, fill = site)) +
  geom_point(aes(x = site, y = data), position = position_jitter(0.05)) +
  scale_x_discrete("Field site") + scale_y_continuous("Length (mm)") +
  theme(legend.position=c(0,1), legend.justification=c(0,1), legend.title=element_blank())
```

## 3. 等分散性の検定 {.scrollable}

箱ひげ図を確認すると，不等分散性の問題はないように見えないが，検定をかけて確認できます。`site` ごとの不偏分散は次の通りです。

```{r}
#| echo: true
X %>% 
  group_by(site) %>% 
  summarise(sigma = var(data))
```

Site A の分散は Site B と Site C と比べると約半分ぐらいです。


**バートレット検定** は正規分布に従わないデータに強く影響されますので，誤った結果になる可能性があります。，
```{r}
#| echo: true
bartlett.test(data ~ site, X)
```

**ルービン検定** は正規分布に従わないデータに対してロバスト (robust, 頑健) です。；

```{r}
#| echo: true
car::leveneTest(data ~ site, X)
```

どちらも，帰無仮説を棄却する結果を示していないので，水準ごとの分散は等しいと解釈できます。

* 第 1 種の過誤を起こす性質： Levene > Bartlett
* 第 2 種の過誤を起こす性質： Bartlett > Levene

:::{.notes}

Levene's test is just a t-test or an ANOVA of the absolute values of the deviations of the data
from their group means. So, the assumptions that need to be satisfied are the same as a t-test or an
ANOVA. However, since it uses the absolute value, the t-test/ANOVA assumptionare are not truely satsified, 
since the value being tested can never be less than 0.

Bartlett's test assumes the data come from a normal distribution.

Note that there is a Brown-Forsythe test, which is a robust Levene's test that uses the absolute deviation
from the median. There are two packages with a function, onewaytests and lawstat. I think the calculation in 
onewaytests is wrong, because it appears to be using the mean and not the median. 
:::

## 4. 分散分析を実施する {.scrollable}

等分散性に問題なかったので，分散分析をします。

```{r}
#| echo: true
m1 = lm(data ~ site, data = X)
anova(m1)
```

分散分析表には，自由度 (`Df`)，平方和 (`Sum Sq`)，平均平方 (`Mean Sq`)，F値 (`F value`)，P値 (`Pr(>F)`) がでます。
P値は有意水準 (α = 0.05) より低いので，帰無仮説 ($\mu_A = \mu_B = \mu_C$) を棄却します。帰無仮説が正しかったら，このデータはとても珍しいです。

```{r}
#| eval: false
#| echo: true
# 手順はいくつかあります。
summary.aov(m1)
lm(data ~ site, data = X) %>% anova()
lm(data ~ site, data = X) %>% summary.aov()
aov(data ~ site, data = X) %>% summary()
```

## 5. 図を用いて残渣の正規性と等分散性を確認する {.smaller}


```{r}
#| fig-width: 8
#| fig-height: 4
plots = lindia::gg_diagnose(m1, plot.all=FALSE) # lindia パッケージが必要です。
lindia::plot_all(plots[c(2,3,4)], ncol = 3)
```

**Residual vs. site** と **Residual vs. Fitted Value** の図は残渣の性質を確認するための図です。
この二つの図で確認するのは，残渣のばらつきとばらつきの性質です。ばらつきが説明変数となんかしらの関係があれば，解析に問題があると示します。**Normal-QQ Plot** は残渣の正規性を確認するための図です。残渣は正規分布に従えば，赤線とかさなります。**この結果をみると，正規性に問題はないが，期待値が高いときの残渣のばらつきは期待値の低いときのばらつきより大きいです。**

:::{.notes}
[https://towardsdatascience.com/a-comprehensive-list-of-handy-r-packages-e85dad294b3d](List of useful R packages.)
:::

## 6. 結果を報告する


結果の報告について，まずは分散分析表の記述が必要です。

```{r}
CAP = "Analysis of variance table"
xout = aov(data ~ site, data = X) %>% summary() 
df = xout[[1]]$Df
fval = xout[[1]]$`F value`
pval = xout[[1]]$`Pr(>F)`
fout = sprintf("F_{(%d, %d)} = %0.2f, P = %0.4f", df[1], df[2], fval[1], pval[1])
CNAMES = c("Treatment", "d.f.", "SS", "MS", "F-value", "P-value")
xout[[1]] %>% as_tibble(rownames="Treatment") %>% 
  knitr::kable(format = "latex", booktabs = TRUE,
               digits = c(NA, 0, 2, 2, 4, 4),
               col.names=CNAMES,
               caption = CAP) 
```

文中に記述するなら，次のとおりです。

> 沿岸域によってアマモの全長が異なるかを，一元配置分散分析によって検討したところ，沿岸域 $(`r fout`)$ の効果は有意だった。

F値，自由度，P値を記述することがポイントです。


# Multiple comparisons

## 分散分析の帰無仮説を棄却したとき

::: {.r-fit-text}
分散分析に帰無仮説を棄却したら，$\mu_1 \ne \mu_2 \ne \cdots \ne \mu_p$ と考えられるが，
水準ごとの違いは明らかではないです。多重比較はペアごとの平均値を比較するときにつかう手法です。2 種類の多重比較があります。

* *a priori* comparisons「事前比較」
    - 分散分析をするまえに，事前に設定した多重比較
* *post hoc* comparisons「事後比較」
    - 分散分析をしたあとにする多重比較

事前比較のとき，第 1 種の誤りは分散分析の $\alpha$ と同じです。
事後比較のとき，第 1 種の誤りを新たに求める必要があります。
:::

::: {.notes}
This site is completely wrong! [http://plaza.umin.ac.jp/~beehappy/stat/com-ph.html](Example of an incorrect site)
:::


## 線型結合

::: {.r-fit-text}

確率変数 $x_1, x_2, \cdots, x_p$ の線型結合は次のように定義します。

$$
L = c_1 x_1 + c_2 x_2 + \cdots + c_p x_p
$$
このとき，$c_i$ はあらかじめ決めたモデル係数です。
:::

## 事前比較

::: {.r-fit-text}
事前比較のとき，あらかじめ決めたモデル係数と平均値の積和（線型結合）はつぎのとおりです。$\Lambda$ は大文字のラムダ ($\lambda$) です。

$$
\Lambda = \sum_i c_i \mu_i
$$
\note{$\Lambda$ is the uppercase version of $\lambda$.}

水準 $i$ の平均値 $\mu_i$ の対比は先ほどの式で表せます。
このとき，$c_i$ はモデルの係数です。

$$
\sum_i c_i = 0
$$
事前比較の線型結合は上の条件を満たさなければなりません。
:::


## 事前比較の線型結合の例

一般的な線型結合の例

$$
L = \left(\frac{1}{p}\right)x_1 +\left(\frac{1}{p}\right)x_2 +\cdots +\left(\frac{1}{p}\right)x_p
$$
事前比較の線型結合の例

$$
L = \left(\frac{1}{3}\right)x_1 +
\left(\frac{1}{3}\right)x_2 +
\left(\frac{1}{3}\right)x_3 -
\left(\frac{1}{2}\right)x_4 -
\left(\frac{1}{2}\right)x_5 
$$
$\rightarrow$ 事前比較の係数の和は  $\frac{1}{3}+\frac{1}{3}+\frac{1}{3}-\frac{1}{2}-\frac{1}{2}=0$.

## 事前比較

::: {.r-fit-text}
直交対比 (orthogonal contrasts) は特別な線型結合です。

複数 ($k$) の対比 ($\Lambda_j = \sum_i c_{ji}\mu_i$, $\Lambda_k = \sum_i c_{ki}\mu_i$) があった場合，

$$
\sum_i  \frac{c_{ji}c_{ki}}{n_i}= 0
$$
さらに上の条件を満たさなければなりません。
:::

:::{.notes}

A contrast is a linear combination of treatment group means ($\mu_i$),

$$
\Lambda = \sum_i c_i \mu_i
$$
where the coefficients $c_i$ are predetermined values that must satisfy the condition $\sum_i c_i = 0$.

If there are $k$ multiple contrasts (e.g., $\Lambda_j = \sum_i c_{ji}\mu_i$, 
$\Lambda_k = \sum_i c_{ki}\mu_i$), and if they satisfy the constraint,

$$
\sum_i  \frac{c_{ji}c_{ki}}{n_i}= 0
$$

then these contrasts are called orthogonal contrasts.

j and k refer to a contrast, and there are there are $J-1$ orthogonal contrasts.
Where $J$ is the number of levels.

Orthogonal contrasts are comparisons that are statistically independent.

If we compare setosa with virginica and setosa with versicolor, we have 
implicitly compared virginica with versicolor.

Choose the contrasts depending on your hypothesis. So if we want to compare
virginica and versicolor with setosa, we must build a contrast matrix to do so.

A contrast matrix has contrast coefficients that must sum to zero. But in R the default
contrasts do not
:::

## 直交対比の例

::: {.r-fit-text}

$\mu_1$, $\mu_2$, $\mu_3$ の平均値と関係するモデル係数の線型結合は次の用な形をとります。

$$
\Lambda = \overbrace{c_1 \mu_1}^{p=1} + \overbrace{c_2 \mu_2}^{p=2} + \overbrace{c_3 \mu_3}^{p=3}
$$
最大 $p-1$ の直交比較は設定できます。このとき，$p=3$ なので，直交比較の数は $2$ です。つまり，ここで設定できる直交比較は
$$
\begin{aligned}
A &= a_1 \mu_1 + a_2 \mu_2 + a_3 \mu_3 \\
B &= b_1 \mu_1 + b_2 \mu_2 + b_3 \mu_3
\end{aligned}
$$

問題は，$\sum_i a_i = 0$，$\sum_i b_i = 0$，$\sum_i \frac{a_i b_i}{n_i}=0$ を満たす係数をきめることです。
:::

## 直交比較の例

::: {.r-fit-text}

係数の組み合わせは無限にありますが，実際には仮説をたててきめます。このとき，$\mu_1 = \mu_2$ と $\frac{1}{2}(\mu_1 + \mu_2) = \mu_3$ が多重比較の帰無仮説としたら，直交比較は次のとおりです。

$$
\begin{aligned}
A &= 1 \mu_1 + (-1) \mu_2 +    0 \mu_3 \\
B &= 1 \mu_1 +   1  \mu_2 + (-2) \mu_3
\end{aligned}
$$

* $\sum_i a_i \rightarrow 1 + (-1) = 0$
* $\sum_i b_i \rightarrow 1 + 1 + (-2) = 0$, 
* $\sum_i \frac{a_i b_i} {n_i} \rightarrow 1\times 1 + (-1)\times 1 + 0\times(-2) = 0$
:::


## 多重比較

::: {.r-fit-text}

* 多重比較（線型比較, linear contrasts）は $p$ 平均値の比較をします。
    * 直交比較を満たさない多重比較の比較は独立ではない。
* 直交比較は (orthogonal contrasts) も $p$ 平均値の比較をしていますが，独立した比較をしています。
    * 独立した比較は $p-1$ あります。
* Family wise error rate (FWER: ファミリーワイズエラー率) を 0.05 におさえるのであれば，各比較の test wise error rate (TWER: テストワイズエラー率) を下げる必要があります。
:::

# Family wise error rate

## FWER 

::: {.r-fit-text}
ファミリーワイズエラー率は多重仮説検定をするときに，全ての仮説のなで，少なくとも１つの第１種の過誤を起こす確率です。FWER の決め方に，数種類の手法があります。

* Bonferroni’s correction 
    * ボンフェローニ補正
* Sidak's procedure 
    * シダックの手法
* Holmes-Bonferroni's procedure 
    * ホルム・ボンフェローニ手法
* Dunnet's correction 
    * ダネット補正
:::

## ボンフェローニ補正

::: {.r-fit-text}

**Bonferroni's correction**

* 帰無仮説 $H_i$ を検定するための P値を $p_i$ とする。
* $p_i \leq \alpha / m$ であれば，$H_i$ を棄却する。
:::


## シダックの手法

::: {.r-fit-text}
**Sidak's procedure**

* TWER は $\alpha_{sidak} = 1 - (1-\alpha)^\frac{1}{m}$
* ボンフェローニ補正より検出力が高い。
:::

## ホルム・ボンフェローニ手法

::: {.r-fit-text}

**Holmes-Bonferroni's procedure**

* P値を最小から最大までにならべ，$P_1, P_2, \cdots, P_n$に対して帰無仮説 $H_1, H_2, \cdots, H_n$とする。
* $P_k \leq \frac{\alpha}{m+1 - k}$ が最大になったときの $k$ は $R$ とする。
* $H_1, \cdots, H_k$ までの帰無仮説を棄却する。
:::

## ダネット補正

::: {.r-fit-text}
**Dunnet's correction**

* 多数の水準を単一の対象水準と比較したいときにつきます。
* ダネット補正のとき，$j-1$回 の比較しかありません。
:::

# More examples on multiple comparisons {.scrollable}

## 花びらの長さの事前比較（直交ではない比較）

$\mu_\text{setosa} = \mu_\text{versicolor} = \mu_\text{virginica}$ の帰無仮説でなくて，$\mu_\text{setosa} = \mu_\text{versicolor}$ と $\mu_\text{setosa} = \mu_\text{virginica}$ が帰無仮説です。

線型結合は次のとおりです。
$$
\begin{aligned}
A &= 1 \mu_\text{setosa} - 1 \mu_\text{versicolor} +    0 \mu_\text{virginica} \\
B &= 1 \mu_\text{setosa} + 0 \mu_\text{versicolor} -    1 \mu_\text{virginica} \\
\end{aligned}
$$


* $\sum_i a_i = 0$ と $\sum_i b_i = 0$ を満たしています。 
* $\sum_i \frac{a_i b_i} {n_i} \rightarrow (1 \times 1) + (-1\times 0) + (0\times-1) = 1$ ので，直交比較の条件を満たしていません。

このときの 2 回比較するので（帰無仮説は２つある），($\alpha_{fwer} = 0.05$) をするなら，ボンフェローニ補正で補正した$\alpha_{twer} = \alpha / 2 = 0.025$ です。直交比較ではないので，帰無仮説は独立していないので，棄却した場合慎重に解釈したほうがいい。

:::{.notes}

[https://stats.stackexchange.com/questions/9751/do-we-need-a-global-test-before-post-hoc-tests/9753](Cross Validated Link: Do we need a global test before post hoc tests?)

Just because the ANOVA can't reject the global null (omnibus test) doesn't mean that you cant run a multiple comparisons test.
However, an ANOVA still needs to be calculated because the mean-square-errors from the ANOVA are used in the multiple comparisons test. 
:::

## 花びらの長さの事前比較（直交比較） {.scrollable}

$\mu_\text{setosa} = \mu_\text{versicolor} = \mu_\text{virginica}$ の帰無仮説でなくて，$\mu_\text{setosa} = \mu_\text{versicolor}$ と $\frac{1}{2}(\mu_\text{setosa} +\mu_\text{versicolor})= \mu_\text{virginica}$ が帰無仮説です。

線型結合は次のとおりです。
$$
\begin{aligned}
A &= 1 \mu_\text{setosa} - 1 \mu_\text{versicolor} +    0 \mu_\text{virginica} \\
B &= 1 \mu_\text{setosa} + 1 \mu_\text{versicolor} -    2 \mu_\text{virginica} \\
\end{aligned}
$$


* $\sum_i a_i = 0$ と $\sum_i b_i = 0$ を満たしています。 
* $\sum_i \frac{a_i b_i} {n_i} \rightarrow (1 \times 1) + (-1\times 1) + (0\times-2) = 0$ ので，直交比較の条件を満たしています。

このときも 2 回比較しているので，各帰無仮説のαは ボンフェローニ補正で補正したものを使用します ($\alpha_{twer} = \alpha / 2 = 0.025$)。直交比較なので，帰無仮説は独立しています。


## R における解析 {.scrollable}

アヤメのデータをつかって事前比較を初回します。まず，データの準備です。


```{r}
#| echo: true

iris_new = iris %>% as_tibble()
iris_new # 内容の確認
```

:::{notes}
In R contrasts() does not return the coefficient for the first level,
because it is implicitly 1.
But when assigning a contrast matrix, the matrix can be of size JxJ and the
first level can be set.
:::

## デフォルト比較は treatment contrasts  {.scrollable}

Rでは，すでに設定されている比較があります。数種類の対比行列は関数で設定できます。

* treatment contrasts 処理対比 (`contr.treatment()`)
* Helmert contrasts ヘルマーと対比・直交対比 (`contr.helmert()`)
* sum to zero contrasts 零和対比 (`contr.sum()`)
* polynomial contrasts 多項式対比 (`contr.poly()`)
* SAS contrasts SAS式対比 (`contr.SAS()`)

 
実際には，これらの関数はコーディング行列を返します。
Rでは，`contr.treatment()` がデフォルトの比較です。

## 処理対比

Rのデフォルト事前比較は処理対比です。線型結合の式は次の通りです。

$$
\begin{aligned}
\Lambda_1 &= 1 \times \text{setosa} - 1 \times \text{versicolor} + 0 \times\text{virginica} \\
\Lambda_2 &= 1 \times \text{setosa} + 0 \times \text{versicolor} - 1 \times\text{virginica}
\end{aligned}
$$

このときの帰無仮説は

* $\mu_\text{setosa} = \mu_\text{veriscolor}$
* $\mu_\text{setosa} = \mu_\text{virginica}$


## R 処理対比  {.scrollable}

`contrasts()` 関数をつかって，アヤメのコーディング行列を確認します。

```{r}
#| echo: true
contrasts(iris_new$Species)
```

対比行列に変換するには，列に 1 を代入した列行列を先に足して，その行列の逆行列をもとめる必要があります。

コーディング行列から対比行列への変換

```{r}
cbind(c(1,1,1), contr.treatment(3)) %>% solve()
```

* 1 行目は `setosa` の平均値
* 2 行目は `setosa` と `versicolor` の平均値の差
* 3 行目は `setosa` と `virginica` の平均値の差

## 処理比較の結果 {.scrollable}

```{r}
#| echo: true
m1 = lm(Petal.Length ~ Species, iris_new)
m1 %>% 
  summary.aov(split = list(Species =list("setosa:versicolor" = 1,
                                         "setosa:virginica" = 2)))
```

事前比較を指定したときに分散分析表です。`setosa` 対
 `versicolor` の対比の有意性はとてもたかいです。$P \leq 2\times 10^{-16}$ でした。
 `setosa` 対 `virginica` の結果も同じです。平均値の差は次のように計算します。
 このとき，`(Interecept)` は `setosa` の平均値です。
 
```{r}
#| echo: true
summary(m1)$coefficients
```
 

## ペア毎の比較 {.scrollable}


$$
\begin{aligned}
\Lambda_1 &= 1 \times \text{setosa} - 1 \times \text{versicolor} + 0 \times\text{virginica} \\
\Lambda_2 &= 0 \times \text{setosa} + 1 \times \text{versicolor} - 1 \times\text{virginica}
\end{aligned}
$$

次の帰無仮説は下記のとおりです。

* $\mu_\text{setosa} = \mu_\text{versicolor}$ 
* $\mu_\text{versicolor} = \mu_\text{virginica}$


対比行列はつぎのとおりです。

```{r}
#| echo: true
X = 
  rbind(c( 1,  0, 0), # 切片
        c(-1,  1, 0), # 帰無仮説１
        c( 0, -1, 1)) # 帰無仮説２

X
```



## ペア毎の比較の結果


```{r}
#| echo: true
Z = X %>% solve()
m2 = lm(Petal.Length ~ Species, iris_new, 
        contrasts=list(Species = Z[, -1]))
m2 %>% summary.aov(split = list(Species = list("setosa - versicolor" = 1,
                                                "versicolor - virginica" = 2)))
```

```{r}
summary(m2)$coefficients
```

:::{notes}
We can also get the F-values with this code.

```
aov(m1) %>% 
  summary(split = list(Species = list(versicolor = 1, virginica = 2)))
```
:::


## 直交対比 {.scrollable}

$$
\begin{aligned}
\Lambda_1 &= 1 \times \text{setosa} - 1 \times \text{versicolor} + 0 \times\text{virginica} \\
\Lambda_2 &= 1 \times \text{setosa} + 1 \times \text{versicolor} - 2 \times\text{virginica}
\end{aligned}
$$

次の帰無仮説は下記のとおりです。

* $\mu_\text{setosa} = \mu_\text{versicolor}$ 
* $\frac{1}{2}(\mu_\text{setosa} + \mu_\text{versicolor}) = \mu_\text{virginica}$


対比行列はつぎのとおりです。

```{r}
#| echo: true
X = 
  rbind(c( 1,  0,  0), # 切片
        c(-1,  1,  0), # 帰無仮説１
        c( 1,  1, -2)) # 帰無仮説２

X
```

## 直交対比の結果


```{r}
#| echo: true
Z = X %>% solve()
m3 = lm(Petal.Length ~ Species, iris_new, 
        contrasts=list(Species = Z[, -1]))
m3 %>% summary.aov(split = list(Species = list("setosa - versicolor" = 1,
                                                "mean - virginica" = 2)))
```

```{r}
#| echo: true
summary(m3)$coefficients
```

:::{notes}

There is only one way to partition the sum-of-squares, so all of the sum-of-squares,
regardless of the comparison are the same!
:::

```{r}
#| echo: true
#| eval: false
lm(Petal.Length ~ Species, iris_new, 
        contrasts=list(Species = contr.helmert(3))) %>% 
  summary.aov(split = list(Species = list(a = 1, b = 2)))


lm(Petal.Length ~ Species, iris_new, 
        contrasts=list(Species = contr.diff(3))) %>% 
  summary.aov(split = list(Species = list(a = 1, b = 2)))


lm(Petal.Length ~ Species, iris_new, 
        contrasts=list(Species = contr.treatment(3))) %>% 
  summary.aov(split = list(Species = list(a = 1, b = 2)))


lm(Petal.Length ~ Species, iris_new, 
        contrasts=list(Species = contr.sum(3))) %>% 
  summary.aov(split = list(Species = list(a = 1, b = 2)))
```

# post hoc comparisons

## 事後比較 {.scrollable}



事前に比較を検討しなかった場合，事後の比較も可能です。事後比較も数種類あります。

* Bonferroni Procedure ボンフェロニ法
* Holm-Bonferroni Method ホルム=ボンフェロニ法
* Tukey's Honest Significant Difference Test テューキーのHSD検定
    * Tukey-Kramer method, Tukey's test
* Scheffe's Method シェッフェの方法
* Dunnett's Test ダネットの検定
* Fisher's Least Significant Difference フィッシャーの最小有意差法
* Duncan's new multiple range test ダンカンの新多重範囲検定

他にもありますが，ダンカンとフィッシャーの検定は第 1 種の過誤を起こしやすいです。
最初の4つは，ペアごとの比較をしますが，ダネットの検定は基準水準との比較だけします。

:::{.notes}

[http://rtutorialseries.blogspot.com/2011/03/r-tutorial-series-anova-pairwise.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed\%3A+RTutorialSeries+\%28R+Tutorial+Series\%29](Link: R Tutorial Series)

:::

## ボンフェロニ法


```{r}
#| echo: true
pairwise.t.test(iris_new$Petal.Length, iris_new$Species, p.adjust.method = "bonferroni" )
```

ボンフェロニ法でファミリワイズエラー率を調整するとき，$\alpha_{\text{fwer}} = \alpha / m$ です。
ここで表示されている P 値は t 検定で求めたP値と $m$ の積です。

## ホルム=ボンフェロニ法 {.scrollable}


```{r}
#| echo: true
pairwise.t.test(iris_new$Petal.Length, iris_new$Species, p.adjust.method = "holm" )
```

ボンフェロニ法ににていますが，有意水準を対比ごとに変えます。
まず，P値の低い値から高い値に並べます。
最初のP値の有意水準は $\alpha / m$ です。次のP値の有意水準は $\alpha / (m-1)$ です。
このように，有意水準を徐々に $\alpha$ に戻します。
ここで表示されているP値も t 検定で求めたP値と $m$ の積です。

## テューキーのHSD法


```{r}
mout = lm(Petal.Length ~ Species, iris_new) %>% aov()
TukeyHSD(mout)
```

テューキーのHSD法は各2水準間の平均値の差の検定を行っています。
t 検定とちがって，求めた統計量はステューデント化範囲の分布にしたます。

## シェッフェの方法 {.scrollable}


```{r}
#| echo: true
mout = lm(Petal.Length ~ Species, iris_new)
dferror = df.residual(mout); mserror = deviance(mout)/dferror; fc = summary(mout)$fstatistic
agricolae::scheffe.test(aov(mout), trt = "Species", # 因子
                        DFerror = dferror, MSerror=mserror, Fc = fc, group = T, console = TRUE)
```

この手法は分散分析のF値と残渣平均平方を用いて，ペア毎の比較を行います。
テューキーのHSD法の方が検出力高いので，一般的に使われていません。

## ダネットの検定

```{r}
#| echo: true
DescTools::DunnettTest(Petal.Length ~ Species, data  = iris_new,
                      control = "versicolor")

```

因子の水準にコントロールがあるとき，他の水準をコントロールと比較することがあります。
このとき，ダネットの検定を使います。対比を制限したテューキーのHSD法もつかえます。

# Multiple comparisons after ANOVA

## 分散分析をしたあとの手順

* 実は，最初から多重比較をするつもりであれば，分散分析をする必要はないです。
分散分析をすることにより，$\alpha_{\text{fwer}}$ をあえて上げています。ところが，
有意性のある分散分析を求めてから，多重仮説検定を行なうことが一般です。

* ANOVA procedure で有意な結果がでて，さらに残渣・正規性に問題がなかったので，多重仮説検定をおこないます。

## 多重比較検定：誤った検定 {.scrollable}

```{r}
set.seed(2019)
mu = c(35, 40, 38)
N = c(10,10,10)
CV = c(0.10, 0.10, 0.10)
sd = mu * CV

X = 
  tibble(mu, sd, N, site = LETTERS[1:3]) %>% 
  mutate(data = pmap(list(mu,sd,N), function(mu, sd, N) rnorm(N, 0,sd)+mu)) %>% 
  unnest(data) %>% 
  mutate(site = as.factor(site))

xout = aov(data ~ site, data = X) %>% summary() 
df = xout[[1]]$Df
fval = xout[[1]]$`F value`
pval = xout[[1]]$`Pr(>F)`
fout = sprintf("F_{(%d, %d)} = %0.2f, P = %0.4f", df[1], df[2], fval[1], pval[1])
```

分散分析の結果は：$`r fout`$ でした。$\mu_A=\mu_B=\mu_C$ を棄却しました。


```{r}
#| echo: true
pairwise.t.test(X$data, X$site, p.adjust.method = "none" )
```


 ファミリワイズエラー率を調整していないときのペアごとの t 検定によって， $\mu_A =\mu_B$ と $\mu_A =\mu_C$ を棄却できました。ところが，$\alpha_\text{fwer}$ を調整していないので，第 1 種の過誤を起こす確率は $1 - (1-\alpha)^m = 1 - (1-0.05)^3 = 0.1426$ ですので，誤って帰無仮説を棄却している可能性は十分あります。

## 多重比較検定：ボンフェロニ法

分散分析の結果は：$`r fout`$ でした。$\mu_A=\mu_B=\mu_C$ を棄却しました。


```{r}
#| echo: true
pairwise.t.test(X$data, X$site, p.adjust.method = "bonferroni" )
```



ファミリワイズエラー率をボンフェロニ法で調整しましたが，ペアごと平均値の差に有意性のある結果は得られなかったが，A--B のP値は 0.052 でした。

## 多重比較検定：ボンフェロニ法 

分散分析の結果は：$`r fout`$ でした。$\mu_A=\mu_B=\mu_C$ を棄却しました。


```{r}
#| echo: true
pairwise.t.test(X$data, X$site, p.adjust.method = "holm" )
```


ホルム=ボンフェロニ法はボンフェロニ法と同様な結果でした。


## 多重比較検定：テューキーのHSD法 {.scrollable}


分散分析の結果は：$`r fout`$ でした。$\mu_A=\mu_B=\mu_C$ を棄却しました。

```{r}
#| echo: true
mout = lm(data ~ site, X) %>% aov()
TukeyHSD(mout)
```

テューキーのHSD法のとき，$\mu_A = \mu_B$ を棄却できましたが，その他の
ペアの帰無仮説を棄却できなかった。**ところが，この解析手順に問題があります。このように，何度も多重仮説検定法を用いて，希望している結果がでるまでおこなうことは誤りです。この手法は P-fishing とよび，帰無仮説の有意性検定の概念に違反しています。** 最初からテューキーのHSD法を使うべきでした。

